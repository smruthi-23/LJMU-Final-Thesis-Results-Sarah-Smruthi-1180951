{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGej1X6XEfpGr1/BfLTmGw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ab0150d39e5a43dc9302a3206ab80832":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1fe84687f084b2493d07f82e6fc00d7","IPY_MODEL_3e6ce6f9ebba4147beffd29ea224321a","IPY_MODEL_6b8d5c2ab76d4a2a86010727b85ca48e"],"layout":"IPY_MODEL_feef7f71153a49e3abee5b6b3dd85cc5"}},"f1fe84687f084b2493d07f82e6fc00d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7879e7f978bc45b78c34b998d6c579b5","placeholder":"​","style":"IPY_MODEL_f13c80ad882c49cc9958e2bfe8f6a192","value":"tokenizer_config.json: 100%"}},"3e6ce6f9ebba4147beffd29ea224321a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_735588005cc346fe8066044788b82a1f","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1561822b787f43738dcfeae13978b734","value":25}},"6b8d5c2ab76d4a2a86010727b85ca48e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_588341156b3d47b6b1b77b137d4d63f3","placeholder":"​","style":"IPY_MODEL_a2ae6800bb704f9ba93b96929c6d7945","value":" 25.0/25.0 [00:00&lt;00:00, 2.36kB/s]"}},"feef7f71153a49e3abee5b6b3dd85cc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7879e7f978bc45b78c34b998d6c579b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f13c80ad882c49cc9958e2bfe8f6a192":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"735588005cc346fe8066044788b82a1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1561822b787f43738dcfeae13978b734":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"588341156b3d47b6b1b77b137d4d63f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2ae6800bb704f9ba93b96929c6d7945":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5f893c763c8435a8a4b29211f715eee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a923aece203845a3853a0238a6cb7c44","IPY_MODEL_d80a4f8d045140a4be5a5e20ceee2e94","IPY_MODEL_409f33eea48648098b03f18e5b3a9aa8"],"layout":"IPY_MODEL_ceb93ae2273845429676edf13638d72d"}},"a923aece203845a3853a0238a6cb7c44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2f8360fdfd048728df4c38495bab86e","placeholder":"​","style":"IPY_MODEL_e1f33d6f85164240accc900306465554","value":"config.json: 100%"}},"d80a4f8d045140a4be5a5e20ceee2e94":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16fb905754ce462e85ec06be9adc3443","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c591babe63d4af3992cf7672b871862","value":482}},"409f33eea48648098b03f18e5b3a9aa8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e829ff2ace094e709a0f09dc364ee967","placeholder":"​","style":"IPY_MODEL_714c6954dfac45c3b375bf9fde51b465","value":" 482/482 [00:00&lt;00:00, 48.3kB/s]"}},"ceb93ae2273845429676edf13638d72d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2f8360fdfd048728df4c38495bab86e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1f33d6f85164240accc900306465554":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16fb905754ce462e85ec06be9adc3443":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c591babe63d4af3992cf7672b871862":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e829ff2ace094e709a0f09dc364ee967":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"714c6954dfac45c3b375bf9fde51b465":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc356d9e2e8b45799b4a6197e3c350c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b1e4bfd1ab24d62afd69588a98499dc","IPY_MODEL_52d55767789844b48346eb7e721a2a9f","IPY_MODEL_5989b894f64d48e1a72dcf974ebf7284"],"layout":"IPY_MODEL_eab0f394cc074f03bbd9eb95342d9788"}},"3b1e4bfd1ab24d62afd69588a98499dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23041bfccf534909ac23035193510097","placeholder":"​","style":"IPY_MODEL_6dd716e57c3a4108bc97d71ae42f34b4","value":"vocab.json: 100%"}},"52d55767789844b48346eb7e721a2a9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aed0af2f312143eeaf7f5fa1d5a4757f","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43a118314be94a70bc5243f698e6a214","value":898823}},"5989b894f64d48e1a72dcf974ebf7284":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64a7563d4c7d40728a9e59df5f2a68e8","placeholder":"​","style":"IPY_MODEL_8b4828a689434491acd70db5ec0f043a","value":" 899k/899k [00:00&lt;00:00, 13.8MB/s]"}},"eab0f394cc074f03bbd9eb95342d9788":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23041bfccf534909ac23035193510097":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dd716e57c3a4108bc97d71ae42f34b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aed0af2f312143eeaf7f5fa1d5a4757f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43a118314be94a70bc5243f698e6a214":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"64a7563d4c7d40728a9e59df5f2a68e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b4828a689434491acd70db5ec0f043a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0365b07c1ec4ae1a54ae44f23098f0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_441dc11aa15a4bf9bc30ca0a894186a1","IPY_MODEL_965f483fdc764efb8e7df72a1ce2caf0","IPY_MODEL_4461f67acafc4ce5bdfbea1f95de5afd"],"layout":"IPY_MODEL_0d80af6955ec42dfab6bf509ee51c62c"}},"441dc11aa15a4bf9bc30ca0a894186a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3d0001bc4fe4cbcb0e9f830d0470a58","placeholder":"​","style":"IPY_MODEL_2a89c010af88451babed02374e8101e4","value":"merges.txt: 100%"}},"965f483fdc764efb8e7df72a1ce2caf0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfd0f3a67dc7446fa1834e46c95f4d96","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0f3d9f1a66848918c5ef498c9bb1fc3","value":456318}},"4461f67acafc4ce5bdfbea1f95de5afd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_505cd980f73e44a5a74ef93a80966223","placeholder":"​","style":"IPY_MODEL_d78f9875b3a1492e93721763b123e05f","value":" 456k/456k [00:00&lt;00:00, 21.9MB/s]"}},"0d80af6955ec42dfab6bf509ee51c62c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3d0001bc4fe4cbcb0e9f830d0470a58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a89c010af88451babed02374e8101e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfd0f3a67dc7446fa1834e46c95f4d96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0f3d9f1a66848918c5ef498c9bb1fc3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"505cd980f73e44a5a74ef93a80966223":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d78f9875b3a1492e93721763b123e05f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e242db7ed5da421ca3d90396ac77e3ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_003562768589442e95207c6f08167af0","IPY_MODEL_fc78284f3f874cf5aee73b2e792d2f4a","IPY_MODEL_c429b0651ee4459a8b7e6ae743d3b957"],"layout":"IPY_MODEL_cdcc15c1389c4020887778f8f8907884"}},"003562768589442e95207c6f08167af0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42bec8601bf64176b85922861f10c287","placeholder":"​","style":"IPY_MODEL_ad5faf705b9242f18d611bef4049039b","value":"tokenizer.json: 100%"}},"fc78284f3f874cf5aee73b2e792d2f4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_947b8d07dd9342e980701446c56e576b","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4ff24e857514bcea87484b7f6b3f447","value":1355863}},"c429b0651ee4459a8b7e6ae743d3b957":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87ede068bbd3466e96a80e392887c6a4","placeholder":"​","style":"IPY_MODEL_82821551885341159d73269afa4fde28","value":" 1.36M/1.36M [00:00&lt;00:00, 40.0MB/s]"}},"cdcc15c1389c4020887778f8f8907884":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42bec8601bf64176b85922861f10c287":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad5faf705b9242f18d611bef4049039b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"947b8d07dd9342e980701446c56e576b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4ff24e857514bcea87484b7f6b3f447":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87ede068bbd3466e96a80e392887c6a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82821551885341159d73269afa4fde28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8183d39242d34c9183279d1c77c2f395":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cdb7d9fa68004247ae1f7752f696fd63","IPY_MODEL_0781fa940a7e4412abe1daa7cfc8a40d","IPY_MODEL_fcf0d646c9c14e4fa3d3a17863efbb2b"],"layout":"IPY_MODEL_7f984c5719b34decb3f9ea85c52a3c76"}},"cdb7d9fa68004247ae1f7752f696fd63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5da51e88fb7149cea2e88afaaaf08a7c","placeholder":"​","style":"IPY_MODEL_41a12a4157ad46248c30f944213c8cdd","value":"model.safetensors: 100%"}},"0781fa940a7e4412abe1daa7cfc8a40d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a7226c89f1b4f6498e02f8ae393b717","max":1421700479,"min":0,"orientation":"horizontal","style":"IPY_MODEL_645dc5e5deac4562a3024f86b4752c0f","value":1421700479}},"fcf0d646c9c14e4fa3d3a17863efbb2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26868b04f0f64a27ba19076a659cdbbf","placeholder":"​","style":"IPY_MODEL_6758c4e650364296b54c7d6f1662e364","value":" 1.42G/1.42G [00:23&lt;00:00, 102MB/s]"}},"7f984c5719b34decb3f9ea85c52a3c76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5da51e88fb7149cea2e88afaaaf08a7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41a12a4157ad46248c30f944213c8cdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a7226c89f1b4f6498e02f8ae393b717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"645dc5e5deac4562a3024f86b4752c0f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26868b04f0f64a27ba19076a659cdbbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6758c4e650364296b54c7d6f1662e364":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"BNgDHNOMnwuK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763998572883,"user_tz":-330,"elapsed":31339,"user":{"displayName":"Sarah Smruthi","userId":"05354743683624481075"}},"outputId":"d5a9693c-4c73-4c57-dfaa-6eca5614d414"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting groq\n","  Downloading groq-0.36.0-py3-none-any.whl.metadata (16 kB)\n","Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting bert-score\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.0.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.9.0+cu126)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.2.2)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.57.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.32.4)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert-score) (25.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.20.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.13.3)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.5.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.36.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (6.0.3)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.7.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2.5.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.2.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\n","Downloading groq-0.36.0-py3-none-any.whl (137 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.3/137.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=9d1f4383881b9bd79b47dea525aaa8a3f4c7443467a355bf0bfa43d1658cee61\n","  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n","Successfully built rouge-score\n","Installing collected packages: rouge-score, groq, bert-score\n","Successfully installed bert-score-0.3.13 groq-0.36.0 rouge-score-0.1.2\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["!pip install groq rouge-score bert-score nltk\n","import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","source":["%%javascript\n","function ClickConnect(){\n","  console.log(\"Clicking\");\n","  document.querySelector(\"colab-toolbar-button#connect\").click();\n","}\n","setInterval(ClickConnect, 60000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"twUCPTesgP78","executionInfo":{"status":"ok","timestamp":1763998572918,"user_tz":-330,"elapsed":29,"user":{"displayName":"Sarah Smruthi","userId":"05354743683624481075"}},"outputId":"46cf40d6-c3ba-4f0c-8967-c77b396529c3"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["function ClickConnect(){\n","  console.log(\"Clicking\");\n","  document.querySelector(\"colab-toolbar-button#connect\").click();\n","}\n","setInterval(ClickConnect, 60000)\n"]},"metadata":{}}]},{"cell_type":"code","source":["# ================================================================\n","# Few-Shot Prompting Pipeline – Groq\n","# ================================================================\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import os, re, json, time, logging\n","from datetime import datetime\n","from pathlib import Path\n","from typing import List, Dict, Any\n","\n","import pandas as pd\n","import numpy as np\n","from groq import Groq   # Groq client\n","\n","# ================================================================\n","# 1. FEW-SHOT EXAMPLES\n","# ================================================================\n","\n","FEWSHOT_SUMMARIES = [\n","    {\"input\": \"Explains attention in transformers and its role in capturing long-range dependencies.\",\n","     \"output\": \"The lecture introduces attention in transformers, showing how query, key, and value vectors enable models to weigh relevant tokens. It contrasts this with RNN limitations and demonstrates gains on translation and summarisation.\"},\n","    {\"input\": \"CNN architecture for image classification.\",\n","     \"output\": \"This tutorial covers convolutional, pooling, and fully connected layers, explaining hierarchical feature extraction and typical training steps for vision classification tasks.\"},\n","    {\"input\": \"Reinforcement learning agents learn by reward feedback.\",\n","     \"output\": \"The session formalises RL with policies, rewards, and value estimation. It compares Q-learning and policy gradients, discusses exploration–exploitation, and highlights robotics and gaming use cases.\"},\n","    {\"input\": \"Prompt engineering improves LLM outputs.\",\n","     \"output\": \"Zero-shot, few-shot, and chain-of-thought prompts are compared. The talk emphasises instruction clarity, role specification, and constraint setting to improve reliability and reasoning.\"},\n","    {\"input\": \"MLOps pipelines for reliable deployment.\",\n","     \"output\": \"The talk explains CI/CD for models, experiment tracking, model registries, and monitoring, with tools such as MLflow and Kubeflow for production-grade ML.\"}\n","]\n","\n","FEWSHOT_TOPICS = [\n","    {\"input\": \"Explaining self-attention and BERT internals.\", \"output\": [\"Natural Language Processing\"]},\n","    {\"input\": \"Building CNNs with pooling for object recognition.\", \"output\": [\"Deep Learning\"]},\n","    {\"input\": \"Learning with rewards via Q-learning.\", \"output\": [\"Reinforcement Learning\"]},\n","    {\"input\": \"Designing prompts to improve LLM reasoning.\", \"output\": [\"Prompt Engineering\"]},\n","    {\"input\": \"Automating ML deployment with pipelines and monitoring.\", \"output\": [\"Mlops\"]},\n","    {\"input\": \"Creating data visualisations and feature analysis.\", \"output\": [\"Data Science\"]},\n","    {\"input\": \"Explaining model fine-tuning for generative image models.\", \"output\": [\"Generative AI\"]},\n","    {\"input\": \"Discussing NLP and ML synergy for LLMs.\", \"output\": [\"Natural Language Processing\", \"Machine Learning\"]},\n","]\n","\n","FEWSHOT_QA = [\n","    {\"q\": \"What does attention allow models to do?\",\n","     \"a\": \"It lets models focus on the most relevant tokens in a sequence.\"},\n","    {\"q\": \"Why are convolutions useful in vision?\",\n","     \"a\": \"They extract local spatial features for image classification.\"},\n","    {\"q\": \"How do agents learn in reinforcement learning?\",\n","     \"a\": \"They learn by maximising cumulative rewards through trial and error.\"},\n","    {\"q\": \"When is few-shot prompting effective?\",\n","     \"a\": \"When limited task-specific data exists but examples guide behaviour.\"},\n","    {\"q\": \"Who typically maintains ML pipelines in production?\",\n","     \"a\": \"Machine learning engineers and DevOps teams.\"}\n","]\n","\n","FEWSHOT_CONCEPTS = [\n","    [\"Self-Attention Mechanism\", \"Query-Key-Value\", \"Positional Encoding\"],\n","    [\"Convolutional Layer\", \"Pooling Operation\", \"Feature Map\"],\n","    [\"Reward Function\", \"Policy Gradient\", \"Q-Learning\"],\n","    [\"Few-Shot Prompting\", \"Chain-of-Thought Reasoning\", \"Instruction Tuning\"],\n","    [\"CI/CD Pipeline\", \"Model Registry\", \"Experiment Tracking\"]\n","]\n","\n","# ================================================================\n","# 2. PATHS & API\n","# ================================================================\n","\n","INPUT_FILE = \"/content/drive/MyDrive/Final Thesis Code/Input/clean_input_30.xlsx\"\n","\n","BASE_OUT = Path(\"/content/drive/MyDrive/Final Thesis Code/Output/FewShot Prompting/llama-3.3-70b-versatile/\")\n","BASE_OUT.mkdir(parents=True, exist_ok=True)\n","\n","FINAL_OUTPUT_FILE = BASE_OUT / \"llama-3.3-70b-versatile_fewshot_full_output.xlsx\"\n","\n","API_KEY_PATH = \"/content/drive/MyDrive/Final Thesis Code/api_keys/groq_key1.txt\"\n","\n","def load_key(path):\n","    with open(path) as f:\n","        return f.read().strip()\n","\n","API_KEY = load_key(API_KEY_PATH)\n","client = Groq(api_key=API_KEY)\n","\n","# ================================================================\n","# 3. GLOBAL CONFIG\n","# ================================================================\n","\n","MODEL_NAME = \"llama-3.3-70b-versatile\"\n","GLOBAL_MIN_GAP = 15\n","LAST_TS = 0.0\n","MAX_CHARS = 2600\n","\n","VALID_TOPICS = [\n","    \"Natural Language Processing\",\"Artificial Intelligence\",\"Prompt Engineering\",\n","    \"Machine Learning\",\"Deep Learning\",\"Reinforcement Learning\",\"Generative AI\",\n","    \"Data Science\",\"Time Series\",\"Statistics\",\"LangChain\",\"Langraph\",\n","    \"Python Programming\",\"Mlops\",\"Agentic AI\",\"Other\"\n","]\n","\n","# ================================================================\n","# 4. LOGGING\n","# ================================================================\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger()\n","\n","# ================================================================\n","# 5. CLEANING & CHUNKING\n","# ================================================================\n","\n","def deep_clean(t):\n","    t = str(t)\n","    t = re.sub(r\"https?://\\S+\", \" \", t)\n","    t = re.sub(r\"\\s+\", \" \", t)\n","    return t.strip()\n","\n","def chunk_text(text, max_chars=MAX_CHARS):\n","    clean = deep_clean(text)\n","    if len(clean) <= max_chars:\n","        return [clean]\n","    sents = re.split(r\"(?<=[.!?])\\s+\", clean)\n","    chunks, cur = [], \"\"\n","    for s in sents:\n","        if len(cur) + len(s) < max_chars:\n","            cur += \" \" + s\n","        else:\n","            chunks.append(cur.strip())\n","            cur = s\n","    if cur.strip(): chunks.append(cur.strip())\n","    return chunks\n","\n","# ================================================================\n","# 6. JSON EXTRACTION\n","# ================================================================\n","\n","def extract_json(txt):\n","    try:\n","        s, e = txt.find(\"{\"), txt.rfind(\"}\")\n","        if s == -1 or e == -1:\n","            return {}\n","        return json.loads(txt[s:e+1])\n","    except:\n","        return {}\n","\n","# ================================================================\n","# 7. GROQ CALL (RELIABLE)\n","# ================================================================\n","\n","def groq_call(prompt, temperature=0.2, retries=3):\n","    global LAST_TS\n","    now = time.time()\n","\n","    if LAST_TS > 0 and now - LAST_TS < GLOBAL_MIN_GAP:\n","        time.sleep(GLOBAL_MIN_GAP - (now - LAST_TS))\n","\n","    for attempt in range(retries):\n","        try:\n","            resp = client.chat.completions.create(\n","                model=MODEL_NAME,\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=temperature,\n","                max_tokens=2048\n","            )\n","            LAST_TS = time.time()\n","            return resp.choices[0].message.content\n","        except Exception as e:\n","            print(f\"Retry {attempt+1}/{retries}: {e}\")\n","            time.sleep(4)\n","\n","    return \"\"\n","\n","# ================================================================\n","# 8. FEW-SHOT TASKS\n","# ================================================================\n","\n","# ------ SUMMARY ------\n","def generate_summary(transcript):\n","    chunks = chunk_text(transcript)\n","    partial = []\n","\n","    fewshot = \"\\n\\n\".join([f\"INPUT: {x['input']}\\nOUTPUT: {x['output']}\" for x in FEWSHOT_SUMMARIES])\n","\n","    for c in chunks:\n","        prompt = f\"\"\"\n","Learn from examples:\n","{fewshot}\n","\n","Now summarise the transcript chunk.\n","Return ONLY JSON:\n","{{\"generated_summary\":\"...\"}}\n","\n","CHUNK:\n","\\\"\\\"\\\"{c}\\\"\\\"\\\"\n","\"\"\"\n","        out = groq_call(prompt, 0.15)\n","        j = extract_json(out)\n","        partial.append(j.get(\"generated_summary\", \"\"))\n","\n","    combined = \" \".join(partial)\n","\n","    final_prompt = f\"\"\"\n","Combine the drafts into a 120–160 word summary.\n","Return ONLY JSON: {{\"generated_summary\":\"...\"}}\n","\n","DRAFTS:\n","\\\"\\\"\\\"{combined}\\\"\\\"\\\"\n","\"\"\"\n","    out2 = groq_call(final_prompt, 0.15)\n","    j2 = extract_json(out2)\n","    return j2.get(\"generated_summary\", \"\")\n","\n","# ------ TOPICS ------\n","def classify_topic(transcript, summary):\n","    text = summary + \" \" + transcript[:2000]\n","\n","    examples = \"\\n\".join(\n","        [f\"INPUT: {x['input']}\\nOUTPUT: {x['output']}\" for x in FEWSHOT_TOPICS]\n","    )\n","\n","    prompt = f\"\"\"\n","Learn from examples:\n","{examples}\n","\n","Pick up to 3 topics from:\n","{', '.join(VALID_TOPICS)}\n","\n","Return JSON: {{\"predicted_topics\":[\"...\"]}}\n","\n","TEXT:\n","\\\"\\\"\\\"{text}\\\"\\\"\\\"\n","\"\"\"\n","    out = groq_call(prompt, 0.1)\n","    j = extract_json(out)\n","    topics = j.get(\"predicted_topics\", [])\n","    if isinstance(topics, str):\n","        topics = [topics]\n","\n","    cleaned = []\n","    for t in topics:\n","        for v in VALID_TOPICS:\n","            if t.lower() == v.lower():\n","                cleaned.append(v)\n","                break\n","\n","    return list(dict.fromkeys(cleaned))[:3] or [\"Other\"]\n","\n","# ------ Q&A ------\n","def generate_qa(transcript):\n","    first = chunk_text(transcript)[0]\n","    examples = \"\\n\".join([f\"Q:{x['q']}\\nA:{x['a']}\" for x in FEWSHOT_QA])\n","\n","    prompt = f\"\"\"\n","Learn QA from examples:\n","{examples}\n","\n","Return JSON: {{\"generated_questions\":[{{\"q\":\"...\",\"a\":\"...\"}}]}}\n","\n","Text:\n","\\\"\\\"\\\"{first}\\\"\\\"\\\"\n","\"\"\"\n","    out = groq_call(prompt, 0.1)\n","    j = extract_json(out)\n","    qas = j.get(\"generated_questions\", [])\n","    lines = []\n","    for qa in qas:\n","        lines.append(f\"Q: {qa.get('q','')}\")\n","        lines.append(f\"A: {qa.get('a','')}\")\n","    return \"\\n\".join(lines)\n","\n","# ------ CONCEPTS ------\n","def generate_concepts(transcript):\n","    first = chunk_text(transcript)[0]\n","    examples = \"\\n\".join([\", \".join(lst) for lst in FEWSHOT_CONCEPTS])\n","\n","    prompt = f\"\"\"\n","Learn from examples:\n","{examples}\n","\n","Extract 10–12 technical concepts.\n","Return JSON: {{\"key_concepts\":[\"...\"]}}\n","\n","Text:\n","\\\"\\\"\\\"{first}\\\"\\\"\\\"\n","\"\"\"\n","    out = groq_call(prompt, 0.15)\n","    j = extract_json(out)\n","    return \", \".join(j.get(\"key_concepts\", []))\n","\n","# ================================================================\n","# 9. MAIN PIPELINE\n","# ================================================================\n","\n","def run_pipeline():\n","    df = pd.read_excel(INPUT_FILE)\n","\n","    if FINAL_OUTPUT_FILE.exists():\n","        old = pd.read_excel(FINAL_OUTPUT_FILE)\n","        processed = set(old[\"row_index\"])\n","        results = old.to_dict(orient=\"records\")\n","        print(f\"Resuming: {len(processed)} rows already completed.\")\n","    else:\n","        processed = set()\n","        results = []\n","\n","    for idx, row in df.iterrows():\n","        if idx in processed:\n","            continue\n","\n","        title = str(row[\"title\"])\n","        transcript = str(row[\"transcript\"])\n","\n","        print(\"\\nProcessing:\", title)\n","\n","        summary = generate_summary(transcript)\n","        topics = classify_topic(transcript, summary)\n","        qa = generate_qa(transcript)\n","        concepts = generate_concepts(transcript)\n","\n","        # ----------- PRINT ALL TASK OUTPUTS TO CONSOLE -----------\n","        print(\"\\n========== OUTPUT FOR ROW\", idx, \"==========\")\n","\n","        print(\"\\nSUMMARY:\\n\")\n","        print(summary)\n","\n","        print(\"\\nTOPIC CLASSIFICATION:\\n\")\n","        print(topics)\n","\n","        print(\"\\nGENERATED Q&A:\\n\")\n","        print(qa)\n","\n","        print(\"\\nKEY CONCEPTS:\\n\")\n","        print(concepts)\n","\n","        print(\"\\n============================================\")\n","\n","        rec = {\n","            \"row_index\": idx,\n","            \"title\": title,\n","            \"summary\": summary,\n","            \"topic_classification\": \", \".join(topics),\n","            \"Q_and_A\": qa,\n","            \"key_concepts\": concepts\n","        }\n","\n","        results.append(rec)\n","        pd.DataFrame(results).to_excel(FINAL_OUTPUT_FILE, index=False)\n","\n","    return pd.DataFrame(results)\n","\n","# ================================================================\n","# 10. RUN\n","# ================================================================\n","\n","df_out = run_pipeline()\n","print(\"Few-Shot pipeline completed successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CX83rxmCgQCX","executionInfo":{"status":"error","timestamp":1764001650480,"user_tz":-330,"elapsed":3047098,"user":{"displayName":"Sarah Smruthi","userId":"05354743683624481075"}},"outputId":"0aaecf24-c52c-455a-bcd5-b373bd535e6a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","Processing: Reinforcement Learning through Human Feedback - EXPLAINED! | RLHF\n","\n","========== OUTPUT FOR ROW 0 ==========\n","\n","SUMMARY:\n","\n","The video discusses reinforcement learning with human feedback, using a grid world example with an agent named Frank. Human feedback accelerates the learning process. Similarly, chat GPT utilizes reinforcement learning through human feedback, with a reward model assessing answer quality and proximal policy optimization fine-tuning the model. This approach enables the model to learn from human input and improve its performance over time.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Reinforcement Learning', 'Machine Learning', 'Deep Learning']\n","\n","GENERATED Q&A:\n","\n","Q: What does attention allow models to do?\n","A: It lets models focus on the most relevant tokens in a sequence.\n","Q: Why are convolutions useful in vision?\n","A: They extract local spatial features for image classification.\n","Q: How do agents learn in reinforcement learning?\n","A: They learn by maximising cumulative rewards through trial and error.\n","Q: When is few-shot prompting effective?\n","A: When limited task-specific data exists but examples guide behaviour.\n","Q: Who typically maintains ML pipelines in production?\n","A: Machine learning engineers and DevOps teams.\n","Q: What is the primary function of transformers in NLP?\n","A: They handle sequential data using self-attention mechanisms.\n","Q: How do generative models learn to generate new data?\n","A: They learn by approximating the distribution of the training data.\n","Q: What is the purpose of regularization in machine learning?\n","A: It prevents overfitting by adding a penalty term to the loss function.\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: Soft Margin SVM and Kernels with CVXOPT - Practical Machine Learning Tutorial with Python p.32\n","\n","========== OUTPUT FOR ROW 1 ==========\n","\n","SUMMARY:\n","\n","This tutorial covers Support Vector Machines, including kernel types and soft margin, with example code and visualization. It discusses solving quadratic programming problems and walks through code using numpy and linal. The speaker covers kernel types, such as linear, polynomial, and Gaussian, and their applications in classification tasks. The video also touches on the implementation of a Support Vector Machine, covering the role of kernels and their types, and references additional resources, including Matthew Blondell's GitHub and Christopher Bishop's book.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Machine Learning', 'Deep Learning']\n","\n","GENERATED Q&A:\n","\n","Q: What is the purpose of using CVX opt in this machine learning tutorial?\n","A: To visualize the impact of kernels on a support Vector machine.\n","Q: What is the alternative library to CVX opt for writing a support Vector machine?\n","A: Lib SVM.\n","Q: What type of problems can CVX opt solve?\n","A: Quadratic programming problems with constraints.\n","Q: What is the equation that the CVX opt solver minimizes?\n","A: (1/2) * x^T * P * x + q^T * x, subject to G * x <= h and A * x == b.\n","Q: Where can the sample code and links to CVX opt be found?\n","A: In the description and the text-based tutorial.\n","\n","KEY CONCEPTS:\n","\n","Support Vector Machine, Kernels, CVX opt, Quadratic Programming Solver, LibSVM, Nonlinear Visualization, Soft Margin, Quadratic Programming, Constraint Optimization, Machine Learning, Pattern Recognition\n","\n","============================================\n","\n","Processing: How to create high-quality outputs with ChatGPT Prompt Engineering | Unlocking the Power of Prompts\n","\n","========== OUTPUT FOR ROW 2 ==========\n","\n","SUMMARY:\n","\n","This section explores the foundation of prompt engineering, focusing on prompts as inputs for large language models. It discusses different types of prompts, such as question prompts and statements, and their key features, including length, language, context, and constraints. Understanding these features is crucial to choose the right prompt for desired outputs and impact the complexity and quality of the output. The section provides examples and explains how to deconstruct prompts to identify their components and constraints, aiming to provide a solid understanding of prompts and their key features to advance prompt engineering.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Prompt Engineering', 'Natural Language Processing']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: LangGraph Crash Course #3 - Agents & Tools - Intro\n","\n","========== OUTPUT FOR ROW 3 ==========\n","\n","SUMMARY:\n","\n","The lecture introduces AI agents as autonomous problem solvers, explaining the react agent pattern that mimics human thinking. This pattern involves alternating between thinking, acting, and observing, enabling agents to solve complex problems using tools and reasoning. By adopting this approach, AI agents can make decisions and take actions to achieve their goals, demonstrating a human-like thought process.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Artificial Intelligence', 'Machine Learning', 'Agentic AI']\n","\n","GENERATED Q&A:\n","\n","Q: What does attention allow models to do?\n","A: It lets models focus on the most relevant tokens in a sequence.\n","Q: Why are convolutions useful in vision?\n","A: They extract local spatial features for image classification.\n","Q: How do agents learn in reinforcement learning?\n","A: They learn by maximising cumulative rewards through trial and error.\n","Q: When is few-shot prompting effective?\n","A: When limited task-specific data exists but examples guide behaviour.\n","Q: Who typically maintains ML pipelines in production?\n","A: Machine learning engineers and DevOps teams.\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: LangGraph Crash Course #9 - Reflection Agent - LangSmith Tracing\n","\n","========== OUTPUT FOR ROW 4 ==========\n","\n","SUMMARY:\n","\n","The speaker reviews the reflection agent system to understand its interaction and role in generating a refined viral tweet. They demonstrate integrating LangChain with Lsmith for tracing and monitoring, setting up environment variables, and running a project. This results in a viral tweet generated through multiple iterations of reflection and refinement by generation and reflection agents, showcasing the system's capabilities.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Natural Language Processing', 'Prompt Engineering', 'LangChain']\n","\n","GENERATED Q&A:\n","\n","Q: What is the purpose of tracing the reflection agent system?\n","A: To understand how the systems work together to deliver the final refined viral tweet.\n","Q: Where will the reflection agent system be traced?\n","A: On a particular website, smith.chain.\n","\n","KEY CONCEPTS:\n","\n","\n","\n","============================================\n","\n","Processing: LangChain Crash Course #7 - Chat Models - Setup\n","\n","========== OUTPUT FOR ROW 5 ==========\n","\n","SUMMARY:\n","\n","The speaker installs and imports the LangChain chat model for OpenAI's gpt-4 model. They discuss initializing an LLM, making API calls, handling errors, and setting environment variables. The speaker demonstrates importing the EnV library to interact with the OpenAI API, retrieving the square root of 49, and accessing the 'content' property. They use a simple prompt to query the LLM and plan to demonstrate sending conversation history to improve response accuracy.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Natural Language Processing', 'LangChain', 'Machine Learning']\n","\n","GENERATED Q&A:\n","\n","Q: What is the purpose of installing the LangChain package for OpenAI?\n","A: To work with OpenAI APIs, specifically the chat model.\n","Q: How do you import the chat model in your file?\n","A: By using the command 'from langchain.openai import ChatOpenAI'.\n","Q: What is the purpose of initializing the model with a specific keyword parameter?\n","A: To specify the model to be used, such as 'gpt-4'.\n","Q: Why is the 'gpt-4' model chosen for this example?\n","A: Because it is the latest model released by OpenAI, which is usually the most advanced but also the most expensive.\n","Q: What is an alternative model to use if you're short on cash?\n","A: The 'gpt-3' model, which is less expensive than the latest models.\n","\n","KEY CONCEPTS:\n","\n","LangChain, OpenAI API, Chat Model, Package Installation, VS Code, Terminal, Module Import, Class Initialization, Model Selection, GBT-4 Model, GPD-3 Model\n","\n","============================================\n","\n","Processing: Python Training Course - Python Sort List\n","\n","========== OUTPUT FOR ROW 6 ==========\n","\n","SUMMARY:\n","\n","The video explains Python's sort method for lists with strings and numbers. It prioritizes uppercase letters, then lowercase, and places numbers before strings. The video provides examples of sorting and reversing lists with mixed data types, demonstrating how the sort method works in different scenarios.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Python Programming']\n","\n","GENERATED Q&A:\n","\n","Q: What happens when you sort a list of strings in Python that contains both uppercase and lowercase letters?\n","A: The sort method puts the words that have a capital uppercase letter first and sorts them alphabetically, and then it sorts the ones with the lowercase first letter alphabetically.\n","Q: How does Python's sort method handle lists that contain both strings and numbers?\n","A: The sort method puts the numbers first and the strings second, regardless of the alphabetical order of the strings.\n","Q: What is the effect of reversing a sorted list in Python that contains both uppercase and lowercase letters?\n","A: The reversed list will have the lowercase letters in reverse alphabetical order followed by the words with uppercase letters at the start in reverse alphabetical order.\n","Q: Why might you need to ensure all strings in a list are either lowercase or uppercase before sorting?\n","A: To ensure the list is sorted in a particular way, as the sort method treats uppercase and lowercase letters differently.\n","Q: What happens when you insert a number into a list of strings in Python and then sort the list?\n","A: The number will be placed at the start of the list, and the strings will be sorted alphabetically after it.\n","\n","KEY CONCEPTS:\n","\n","Lists in Python, Sort Method, String Sorting, Case Sensitivity, Alphabetical Order, Reverse Sorting, Mixed Data Types, Number Sorting, List Insertion, Python Data Handling\n","\n","============================================\n","\n","Processing: \n","Humans vs. AI: Who should make the decision?\n","\n","========== OUTPUT FOR ROW 7 ==========\n","\n","SUMMARY:\n","\n","The talk explores human-AI collaboration in decision-making, using a fraud detection system as an example. It highlights the strengths of both humans and AI, with AI excelling in confident predictions and humans performing better in uncertain cases. The speaker discusses the limitations of AI and human decision-making, and the benefits of augmented intelligence, which combines both. However, human cognitive bias and the presentation of AI recommendations can impact decision-making. The talk discusses how augmented intelligence can improve outcomes by minimizing bias, and how decisions can be made by humans, AI, or a combination of both, leading to optimal results.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Artificial Intelligence', 'Machine Learning']\n","\n","GENERATED Q&A:\n","\n","Q: What is the role of confidence scores in a fraud detection system?\n","A: Confidence scores track the certainty of a prediction, with 0% indicating a false positive and 100% indicating a real alert.\n","Q: How do human and AI performance curves differ in fraud detection?\n","A: Human performance curves are typically flatter, with better performance when AI is unsure, while AI curves are more correlated to high success rates at high confidence scores.\n","Q: When do humans outperform AI in decision-making?\n","A: Humans outperform AI when the AI is unsure, typically in complex or statistically rare cases, by bringing in additional information and context.\n","Q: What is the benefit of using AI in fraud detection?\n","A: AI can help alleviate the workload of financial analysts by handling alerts with high confidence scores, allowing humans to focus on more complex cases.\n","Q: Why do humans lose to AI in certain tasks?\n","A: Humans can lose consistency, focus, and attention, while AI algorithms do not get distracted and can perform highly when certain of themselves.\n","\n","KEY CONCEPTS:\n","\n","Artificial Intelligence, Fraud Detection System, False Positives, Confidence Score, Success Rate, AI Performance Curve, Human Performance Curve, Machine Learning, Prediction Model, Decision Making, Pattern Recognition\n","\n","============================================\n","\n","Processing: \n","Build generative apps faster with Vertex AI\n","\n","========== OUTPUT FOR ROW 8 ==========\n","\n","SUMMARY:\n","\n","Dimitrius, a Google product manager, discusses new Vertex AI APIs for building generative applications. These APIs include document understanding, embedding, vector search, ranking, grounded generation, and fact-checking, aiming to solve technical challenges and improve application quality. The APIs are designed to enhance the development of generative applications, providing tools to overcome common obstacles and create more effective solutions.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Generative AI', 'Natural Language Processing', 'Machine Learning']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: Unitary Transformations\n","\n","========== OUTPUT FOR ROW 9 ==========\n","\n","SUMMARY:\n","\n","The lecture discusses the singular value decomposition (SVD) of a matrix X, where X = U Σ V^T, with U and V as unitary matrices preserving vector angles and lengths. Unitary transformations, like the Fourier transform, are essential in science and engineering. The economy SVD and its geometric interpretation are explained, where X maps a unit sphere to an ellipsoid. The lecture also covers complex-valued data and the use of complex conjugate transpose, highlighting the importance of SVD in various fields.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Data Science']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: \n","Hands On With Google Gemini 1.5 Pro- Is this the Best LLM Model?\n","\n","========== OUTPUT FOR ROW 10 ==========\n","\n","SUMMARY:\n","\n","The video introduces Google Gemini Pro 1.5, a multimodal model for building generative AI-powered applications. It provides a demo, hands-on examples, and guidance on creating an API key and implementing the model for text and image processing. The model can process up to 1 million multimodal tokens, extract comedic moments, and identify scenes from drawings. The speaker demonstrates how to use the API to build applications, such as generative apps, and provides examples of generating text and responding to questions. The goal is to understand how to use the API to provide a better experience for end-users.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Generative AI', 'Deep Learning', 'Natural Language Processing']\n","\n","GENERATED Q&A:\n","\n","Q: What is Google Gemini Pro 1.5?\n","A: It's a multi-model that can work with both text and images.\n","Q: What kind of applications can be built using Google Gemini Pro 1.5?\n","A: Generative AI powered applications.\n","Q: What will be covered in the video?\n","A: A demo video, hands-on application, and implementation of creating an API key and using it.\n","Q: What is the significance of Google Gemini Pro 1.5 being a multi-model?\n","A: It allows the model to work with both text and images.\n","Q: What is the first step in the video?\n","A: Showing a demo video to give an idea of what Google Gemini Pro 1.5 can do.\n","\n","KEY CONCEPTS:\n","\n","Generative AI, Google Gemini Pro 1.5, Multi-Model, API Key, Long Context Understanding, Experimental Feature, Deep Learning, Natural Language Processing, Computer Vision, Machine Learning, Model Implementation, API Integration\n","\n","============================================\n","\n","Processing: How to evaluate large language models using Prompt Engineering | Testing and Improving with PyTorch\n","\n","========== OUTPUT FOR ROW 11 ==========\n","\n","SUMMARY:\n","\n","The session focuses on evaluating and testing prompt engineering models. It covers various matrices like perplexity, accuracy, and human evaluation. Techniques for debugging and improving these models are also discussed, including analyzing generated responses and testing on different datasets. The goal is to assess and enhance the performance of prompt engineering models, ensuring they provide accurate and reliable results.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Prompt Engineering', 'Natural Language Processing', 'Machine Learning']\n","\n","GENERATED Q&A:\n","\n","Q: What does attention allow models to do?\n","A: It lets models focus on the most relevant tokens in a sequence.\n","Q: Why are convolutions useful in vision?\n","A: They extract local spatial features for image classification.\n","Q: How do agents learn in reinforcement learning?\n","A: They learn by maximising cumulative rewards through trial and error.\n","Q: When is few-shot prompting effective?\n","A: When limited task-specific data exists but examples guide behaviour.\n","Q: Who typically maintains ML pipelines in production?\n","A: Machine learning engineers and DevOps teams.\n","Q: What is the primary function of recurrent neural networks?\n","A: They process sequential data, such as time series or natural language.\n","Q: How do transformers handle long-range dependencies?\n","A: They use self-attention mechanisms to weigh the importance of different input elements.\n","Q: What is the purpose of data preprocessing in machine learning?\n","A: It prepares the data for training by handling missing values, normalization, and feature scaling.\n","Q: What type of learning occurs when models are trained on labeled data?\n","A: Supervised learning.\n","Q: What is the goal of clustering algorithms in unsupervised learning?\n","A: To group similar data points into clusters based on their features.\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: Generative AI vs AI agents vs Agentic AI\n","\n","========== OUTPUT FOR ROW 12 ==========\n","\n","SUMMARY:\n","\n","The lecture discusses the differences between generative AI, AI agents, and agentic AI, highlighting their increasing complexity and capabilities. It explains how these AI types range from simple Q&A to autonomous decision-making and multi-step task completion. Agentic AI can use tools, knowledge, and other agents to reach a goal, demonstrating advanced autonomous capabilities. The lecture provides an overview of the evolving landscape of AI, from basic to complex systems, and their potential applications.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Artificial Intelligence', 'Generative AI', 'Agentic AI']\n","\n","GENERATED Q&A:\n","\n","Q: What does attention allow models to do?\n","A: It lets models focus on the most relevant tokens in a sequence.\n","Q: Why are convolutions useful in vision?\n","A: They extract local spatial features for image classification.\n","Q: How do agents learn in reinforcement learning?\n","A: They learn by maximising cumulative rewards through trial and error.\n","Q: When is few-shot prompting effective?\n","A: When limited task-specific data exists but examples guide behaviour.\n","Q: Who typically maintains ML pipelines in production?\n","A: Machine learning engineers and DevOps teams.\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: \n","Covariance in Statistics\n","\n","========== OUTPUT FOR ROW 13 ==========\n","\n","SUMMARY:\n","\n","The lecture discusses covariance, a measure to quantify the relationship between two random variables. It explains the equation for covariance, comparing it to variance, and demonstrates how it works with examples. Scenarios where one variable increases as the other increases or decreases are explored, resulting in positive or negative covariance values. This explanation helps to understand how covariance works and its significance in measuring relationships between variables.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Statistics', 'Data Science']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: 3. Objective || End to End AI Tutorial\n","\n","========== OUTPUT FOR ROW 14 ==========\n","\n","SUMMARY:\n","\n","The video discusses defining the objective of a reinforcement learning problem, where an agent learns to maximize a numerical reward signal by interacting with an environment. It aims to learn an optimal policy mapping states to actions through methods like value-based or policy-based approaches. Examples like Tic-Tac-Toe and stock market trading illustrate how to define rewards and parameterize the agent's objective, with the goal of maximizing the expected cumulative reward over time.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Reinforcement Learning']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: Python Training - Python Dictionary Basics\n","\n","========== OUTPUT FOR ROW 15 ==========\n","\n","SUMMARY:\n","\n","This tutorial covers dictionaries in Python, including declaration, key-value pairs, and functions like items, keys, and values. It demonstrates creating dictionaries from lists, accessing and modifying values, and deleting entries, highlighting their importance in Python, especially for data science with pandas.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Python Programming', 'Data Science']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: \n","Fight Insider Threats with AI-infused SIEM\n","\n","========== OUTPUT FOR ROW 16 ==========\n","\n","SUMMARY:\n","\n","The session explores how AI and machine learning enhance security posture by leveraging user behavior analytics to detect and respond to insider threats. Integrating User Behavior Analytics (UBA) with a Security Information and Event Management (SIEM) solution helps security professionals detect and respond to insider threats more effectively. Machine learning identifies anomalies and potential threats in user behavior, reducing breach containment time and costs.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Artificial Intelligence', 'Machine Learning', 'Data Science']\n","\n","GENERATED Q&A:\n","\n","Q: What can AI potentially do for Security Professionals?\n","A: Help stay ahead of emerging threats and improve organization security posture\n","Q: How many fewer days did it take to identify and contain a data breach with extensive AI and automation use?\n","A: 108 days on average\n","Q: What is the purpose of User Behavior Analytics (UBA) with AI and machine learning?\n","A: To detect and respond to Insider threats quickly and precisely\n","Q: What is the average cost of an Insider threat for an organization?\n","A: $4 million\n","Q: What report was based on a survey of over 500 organizations?\n","A: IBM's Cost of a Data Breach Report 2023\n","\n","KEY CONCEPTS:\n","\n","AI, Machine Learning, User Behavior Analytics, Insider Threats, Data Breach, Automation, Security Posture, Threat Detection, Response Time, Incident Containment\n","\n","============================================\n","\n","Processing: Meta Llama 3 Is Here- And It Will Rule the Open Source LLM Models\n","\n","========== OUTPUT FOR ROW 17 ==========\n","\n","SUMMARY:\n","\n","Krishak introduces Llama 3, an open-source large language model developed by Meta, highlighting its impressive performance metrics and capabilities. Llama 3 boasts improved scalability, contextual understanding, and complex task handling, making it a strong competitor to paid models. The model is available on platforms like Meta, Hugging Face, and Kaggle, with step-by-step instructions provided for access and download. Krishak shares links to Hugging Face repositories and instructions for installation and local inference with Llama 3, making it easily accessible to users.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Natural Language Processing', 'Machine Learning', 'Generative AI']\n","\n","GENERATED Q&A:\n","\n","Q: What is the speaker introducing at the beginning of the video?\n","A: The speaker is introducing themselves and their YouTube channel.\n","Q: What time is it when the speaker starts talking?\n","A: It is 2 a.m.\n","\n","KEY CONCEPTS:\n","\n","\n","\n","============================================\n","\n","Processing: Getting Started With sklearn\n","\n","========== OUTPUT FOR ROW 18 ==========\n","\n","SUMMARY:\n","\n","The lecture covers implementing a decision boundary using Python and scikit-learn, focusing on the Naive Bayes algorithm. It guides the audience to explore the library's documentation and use cases, including Gaussian Naive Bayes, providing a comprehensive understanding of the topic.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Machine Learning', 'Python Programming', 'Data Science']\n","\n","GENERATED Q&A:\n","\n","Q: What library is being used in the lesson?\n","A: scikit-learn, often abbreviated as sk-learn\n","Q: What algorithm is being used in the code?\n","A: Naive Bayes, specifically Gaussian Naive Bayes\n","Q: Where can you find documentation for the scikit-learn library?\n","A: Google, by searching for 'sklearn' and the name of the algorithm\n","Q: What is the purpose of using Google in this context?\n","A: To find documentation and use cases for the scikit-learn library and its functions\n","Q: What will the viewer be able to do by the end of the next video or two?\n","A: Write the Python code for the decision boundary themselves\n","\n","KEY CONCEPTS:\n","\n","\n","\n","============================================\n","\n","Processing: \n","Log Normal Distribution in Statistics\n","\n","========== OUTPUT FOR ROW 19 ==========\n","\n","SUMMARY:\n","\n","The lecture covers Gaussian and log normal distributions, explaining their characteristics, such as the bell curve and symmetry. It provides examples of real-world data that follow these distributions, like height and income. The lecture also discusses how to identify and work with these distributions, including standard scaling and log normalization, to improve model accuracy in machine learning. Key concepts include understanding distribution properties and applying transformations to enhance model performance.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Statistics']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: \n","Deep learning project end to end | Potato Disease Classification Using CNN - 1 : Problem Statement\n","\n","========== OUTPUT FOR ROW 20 ==========\n","\n","SUMMARY:\n","\n","This video series covers a deep learning project in agriculture, focusing on building a mobile app to detect potato diseases using convolutional neural networks. It covers image collection and pre-processing, building and deploying a CNN model, and creating a website and mobile app. The project utilizes TensorFlow, TF Serving, and React JS, with prerequisites including basic Python and deep learning knowledge. The series aims to reduce economic losses for farmers through early disease detection and treatment, and is valuable for machine learning engineers and data scientists.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Deep Learning', 'Machine Learning', 'Data Science']\n","\n","GENERATED Q&A:\n","\n","Q: What is the main goal of the deep learning project series in the agriculture domain?\n","A: To build an end-to-end application for detecting diseases in potato plants using deep learning and convolutional neural networks.\n","Q: What are the two common diseases that can happen to a potato plant?\n","A: Early blight and late blight.\n","Q: What is the role of the data scientist in the AtliQ Agriculture project?\n","A: To work on the project and build the whole application end-to-end, starting with gathering data.\n","Q: How will the mobile application detect diseases in potato plants?\n","A: By using deep learning and convolutional neural networks to analyze pictures of the plants taken by the farmer.\n","Q: What is the first step in any supervised machine learning project?\n","A: Data collection.\n","\n","KEY CONCEPTS:\n","\n","Deep Learning, Convolutional Neural Network, ML Ops, TF Serving, Fast API, Google Cloud, Google Cloud Functions, React Native, Mobile App Development, Supervised Machine Learning, Data Collection\n","\n","============================================\n","\n","Processing: LangGraph Crash Course #2 - Levels of Autonomy in LLM applications\n","\n","========== OUTPUT FOR ROW 21 ==========\n","\n","SUMMARY:\n","\n","The lecture discusses levels of autonomy in LLM applications, from zero autonomy to completely autonomous agents. It covers single LLM calls, chains, routers, and state machines, highlighting their advantages and disadvantages. State machines, or agents, can control flow, learn, and adapt, making them more intelligent and autonomous. The lecture introduces Landgraph, a technology enabling state machines and agents, with potential to disrupt various industries by providing more intelligent and autonomous solutions.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Natural Language Processing', 'Artificial Intelligence', 'Langraph']\n","\n","GENERATED Q&A:\n","\n","Q: What does attention allow models to do?\n","A: It lets models focus on the most relevant tokens in a sequence.\n","Q: Why are convolutions useful in vision?\n","A: They extract local spatial features for image classification.\n","Q: How do agents learn in reinforcement learning?\n","A: They learn by maximising cumulative rewards through trial and error.\n","Q: When is few-shot prompting effective?\n","A: When limited task-specific data exists but examples guide behaviour.\n","Q: Who typically maintains ML pipelines in production?\n","A: Machine learning engineers and DevOps teams.\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: Introduction to Advanced Topics in Prompt Engineering using Pre-Trained Large Language Models\n","\n","========== OUTPUT FOR ROW 22 ==========\n","\n","SUMMARY:\n","\n","This section covers advanced prompt engineering topics, including handling text, image, and audio-based prompts, fine-tuning pre-trained models, and data pre-processing. It also discusses ethical considerations like fairness and privacy, and provides practical exercises. The section aims to equip readers with skills to deploy prompt engineering models in production, using techniques like multitask learning and distillation, while addressing important ethical concerns.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Prompt Engineering', 'Deep Learning', 'Machine Learning']\n","\n","GENERATED Q&A:\n","\n","Q: What is the primary function of batch normalization in deep learning?\n","A: It normalizes the input data for each layer to improve model stability and training speed.\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: SVD: Eigen Action Heros [Matlab]\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99616, Requested 3314. Please try again in 42m11.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99611, Requested 3314. Please try again in 42m7.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99607, Requested 3314. Please try again in 42m3.744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99672, Requested 715. Please try again in 5m34.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99667, Requested 715. Please try again in 5m30.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99663, Requested 715. Please try again in 5m26.592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99979, Requested 129. Please try again in 1m33.312s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99974, Requested 129. Please try again in 1m28.992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99970, Requested 129. Please try again in 1m25.536s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","\n","========== OUTPUT FOR ROW 23 ==========\n","\n","SUMMARY:\n","\n","No transcript chunk was provided to create a summary.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Other']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","\n","\n","============================================\n","\n","Processing: LangChain Crash Course #3 - What is LangChain?\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99965, Requested 775. Please try again in 10m39.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99960, Requested 775. Please try again in 10m35.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99955, Requested 775. Please try again in 10m30.72s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99951, Requested 378. Please try again in 4m44.256s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99946, Requested 378. Please try again in 4m39.936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99941, Requested 378. Please try again in 4m35.616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99983, Requested 696. Please try again in 9m46.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99978, Requested 696. Please try again in 9m42.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99974, Requested 696. Please try again in 9m38.88s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99969, Requested 654. Please try again in 8m58.272s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99964, Requested 654. Please try again in 8m53.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99959, Requested 654. Please try again in 8m49.631999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99955, Requested 608. Please try again in 8m6.431999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99950, Requested 608. Please try again in 8m2.111999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99945, Requested 608. Please try again in 7m57.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","\n","========== OUTPUT FOR ROW 24 ==========\n","\n","SUMMARY:\n","\n","There are no drafts to combine. Please provide the necessary text to create a summary.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Other']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","\n","\n","============================================\n","\n","Processing: How To Use Residuals For Time Series Forecasting\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99941, Requested 296. Please try again in 3m24.768s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99936, Requested 296. Please try again in 3m20.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99931, Requested 296. Please try again in 3m16.128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99926, Requested 1994. Please try again in 27m38.88s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99922, Requested 1994. Please try again in 27m35.424s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 1994. Please try again in 27m31.103999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99912, Requested 786. Please try again in 10m3.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99908, Requested 786. Please try again in 9m59.616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99903, Requested 786. Please try again in 9m55.296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99968, Requested 663. Please try again in 9m5.183999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99963, Requested 663. Please try again in 9m0.864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99959, Requested 663. Please try again in 8m57.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99954, Requested 175. Please try again in 1m51.455999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99949, Requested 175. Please try again in 1m47.136s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99945, Requested 175. Please try again in 1m43.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","\n","========== OUTPUT FOR ROW 25 ==========\n","\n","SUMMARY:\n","\n","There are no drafts to combine. Please provide the necessary text to create a summary.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Other']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: \n","Build a Text-to-SQL Agent for Smarter Database Queries\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99983, Requested 887. Please try again in 12m31.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99978, Requested 887. Please try again in 12m27.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99974, Requested 887. Please try again in 12m23.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99969, Requested 854. Please try again in 11m51.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99964, Requested 854. Please try again in 11m46.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99959, Requested 854. Please try again in 11m42.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99955, Requested 882. Please try again in 12m3.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99950, Requested 882. Please try again in 11m58.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99945, Requested 882. Please try again in 11m54.528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99941, Requested 882. Please try again in 11m51.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99936, Requested 882. Please try again in 11m46.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99931, Requested 882. Please try again in 11m42.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99926, Requested 839. Please try again in 11m0.959999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99922, Requested 839. Please try again in 10m57.504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99917, Requested 839. Please try again in 10m53.184s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99912, Requested 882. Please try again in 11m26.016s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99908, Requested 882. Please try again in 11m22.56s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99903, Requested 882. Please try again in 11m18.239999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99898, Requested 882. Please try again in 11m13.92s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99893, Requested 882. Please try again in 11m9.6s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99889, Requested 882. Please try again in 11m6.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99884, Requested 900. Please try again in 11m17.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99879, Requested 900. Please try again in 11m13.056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99874, Requested 900. Please try again in 11m8.736s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99870, Requested 847. Please try again in 10m19.488s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99865, Requested 847. Please try again in 10m15.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99860, Requested 847. Please try again in 10m10.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99856, Requested 411. Please try again in 3m50.688s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99851, Requested 411. Please try again in 3m46.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99846, Requested 411. Please try again in 3m42.047999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99911, Requested 738. Please try again in 9m20.736s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99906, Requested 738. Please try again in 9m16.416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99902, Requested 738. Please try again in 9m12.96s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99897, Requested 766. Please try again in 9m32.832s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99892, Requested 766. Please try again in 9m28.512s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99887, Requested 766. Please try again in 9m24.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99883, Requested 720. Please try again in 8m40.991999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99878, Requested 720. Please try again in 8m36.672s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99873, Requested 720. Please try again in 8m32.352s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","\n","========== OUTPUT FOR ROW 26 ==========\n","\n","SUMMARY:\n","\n","There are no drafts to combine. Please provide the necessary text to create a summary.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Other']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","\n","\n","============================================\n","\n","Processing: Learn Prompt Engineering from Scratch: Master the Art of Text Generation - Introduction\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99868, Requested 716. Please try again in 8m24.575999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99864, Requested 716. Please try again in 8m21.119999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99859, Requested 716. Please try again in 8m16.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99924, Requested 606. Please try again in 7m37.92s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99919, Requested 606. Please try again in 7m33.6s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99914, Requested 606. Please try again in 7m29.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99910, Requested 595. Please try again in 7m16.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99905, Requested 595. Please try again in 7m12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99900, Requested 595. Please try again in 7m7.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99896, Requested 549. Please try again in 6m24.48s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99891, Requested 549. Please try again in 6m20.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99886, Requested 549. Please try again in 6m15.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","\n","========== OUTPUT FOR ROW 27 ==========\n","\n","SUMMARY:\n","\n","There are no drafts to combine. Please provide the necessary text to create a summary.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Other']\n","\n","GENERATED Q&A:\n","\n","\n","\n","KEY CONCEPTS:\n","\n","\n","\n","============================================\n","\n","Processing: Q-learning - Explained!\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99881, Requested 296. Please try again in 2m32.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99877, Requested 296. Please try again in 2m29.472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99872, Requested 296. Please try again in 2m25.152s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99867, Requested 1349. Please try again in 17m30.624s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99862, Requested 1349. Please try again in 17m26.303999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99858, Requested 1349. Please try again in 17m22.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99853, Requested 885. Please try again in 10m37.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99848, Requested 885. Please try again in 10m33.312s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99844, Requested 885. Please try again in 10m29.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99839, Requested 702. Please try again in 7m47.424s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99834, Requested 702. Please try again in 7m43.104s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99829, Requested 702. Please try again in 7m38.784s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 1/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99894, Requested 638. Please try again in 7m39.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 2/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99889, Requested 638. Please try again in 7m35.328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Retry 3/3: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k5knw813e26rfgrs0dt4z54f` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99885, Requested 638. Please try again in 7m31.872s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-507656289.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;31m# ================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m \u001b[0mdf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Few-Shot pipeline completed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-507656289.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mqa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_qa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mconcepts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_concepts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-507656289.py\u001b[0m in \u001b[0;36mgenerate_qa\u001b[0;34m(transcript)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;31m\\\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \"\"\"\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroq_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mqas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generated_questions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-507656289.py\u001b[0m in \u001b[0;36mgroq_call\u001b[0;34m(prompt, temperature, retries)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             resp = client.chat.completions.create(\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/groq/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    462\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \"\"\"\n\u001b[0;32m--> 464\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    465\u001b[0m             \u001b[0;34m\"/openai/v1/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             body=maybe_transform(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     def patch(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1028\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                     \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m                     self._sleep_for_retry(\n\u001b[0m\u001b[1;32m   1031\u001b[0m                         \u001b[0mretries_taken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretries_taken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                         \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36m_sleep_for_retry\u001b[0;34m(self, retries_taken, max_retries, options, response)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retrying request to %s in %f seconds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     def _process_response(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# ================================================================\n","# Few-Shot Prompting Pipeline – Groq\n","# ================================================================\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import os, re, json, time, logging\n","from datetime import datetime\n","from pathlib import Path\n","from typing import List, Dict, Any\n","\n","import pandas as pd\n","import numpy as np\n","from groq import Groq   # Groq client\n","\n","# ================================================================\n","# 1. FEW-SHOT EXAMPLES\n","# ================================================================\n","\n","FEWSHOT_SUMMARIES = [\n","    {\"input\": \"Explains attention in transformers and its role in capturing long-range dependencies.\",\n","     \"output\": \"The lecture introduces attention in transformers, showing how query, key, and value vectors enable models to weigh relevant tokens. It contrasts this with RNN limitations and demonstrates gains on translation and summarisation.\"},\n","    {\"input\": \"CNN architecture for image classification.\",\n","     \"output\": \"This tutorial covers convolutional, pooling, and fully connected layers, explaining hierarchical feature extraction and typical training steps for vision classification tasks.\"},\n","    {\"input\": \"Reinforcement learning agents learn by reward feedback.\",\n","     \"output\": \"The session formalises RL with policies, rewards, and value estimation. It compares Q-learning and policy gradients, discusses exploration–exploitation, and highlights robotics and gaming use cases.\"},\n","    {\"input\": \"Prompt engineering improves LLM outputs.\",\n","     \"output\": \"Zero-shot, few-shot, and chain-of-thought prompts are compared. The talk emphasises instruction clarity, role specification, and constraint setting to improve reliability and reasoning.\"},\n","    {\"input\": \"MLOps pipelines for reliable deployment.\",\n","     \"output\": \"The talk explains CI/CD for models, experiment tracking, model registries, and monitoring, with tools such as MLflow and Kubeflow for production-grade ML.\"}\n","]\n","\n","FEWSHOT_TOPICS = [\n","    {\"input\": \"Explaining self-attention and BERT internals.\", \"output\": [\"Natural Language Processing\"]},\n","    {\"input\": \"Building CNNs with pooling for object recognition.\", \"output\": [\"Deep Learning\"]},\n","    {\"input\": \"Learning with rewards via Q-learning.\", \"output\": [\"Reinforcement Learning\"]},\n","    {\"input\": \"Designing prompts to improve LLM reasoning.\", \"output\": [\"Prompt Engineering\"]},\n","    {\"input\": \"Automating ML deployment with pipelines and monitoring.\", \"output\": [\"Mlops\"]},\n","    {\"input\": \"Creating data visualisations and feature analysis.\", \"output\": [\"Data Science\"]},\n","    {\"input\": \"Explaining model fine-tuning for generative image models.\", \"output\": [\"Generative AI\"]},\n","    {\"input\": \"Discussing NLP and ML synergy for LLMs.\", \"output\": [\"Natural Language Processing\", \"Machine Learning\"]},\n","]\n","\n","FEWSHOT_QA = [\n","    {\"q\": \"What does attention allow models to do?\",\n","     \"a\": \"It lets models focus on the most relevant tokens in a sequence.\"},\n","    {\"q\": \"Why are convolutions useful in vision?\",\n","     \"a\": \"They extract local spatial features for image classification.\"},\n","    {\"q\": \"How do agents learn in reinforcement learning?\",\n","     \"a\": \"They learn by maximising cumulative rewards through trial and error.\"},\n","    {\"q\": \"When is few-shot prompting effective?\",\n","     \"a\": \"When limited task-specific data exists but examples guide behaviour.\"},\n","    {\"q\": \"Who typically maintains ML pipelines in production?\",\n","     \"a\": \"Machine learning engineers and DevOps teams.\"}\n","]\n","\n","FEWSHOT_CONCEPTS = [\n","    [\"Self-Attention Mechanism\", \"Query-Key-Value\", \"Positional Encoding\"],\n","    [\"Convolutional Layer\", \"Pooling Operation\", \"Feature Map\"],\n","    [\"Reward Function\", \"Policy Gradient\", \"Q-Learning\"],\n","    [\"Few-Shot Prompting\", \"Chain-of-Thought Reasoning\", \"Instruction Tuning\"],\n","    [\"CI/CD Pipeline\", \"Model Registry\", \"Experiment Tracking\"]\n","]\n","\n","# ================================================================\n","# 2. PATHS & API\n","# ================================================================\n","\n","INPUT_FILE = \"/content/drive/MyDrive/Final Thesis Code/Input/clean_input_30.xlsx\"\n","\n","BASE_OUT = Path(\"/content/drive/MyDrive/Final Thesis Code/Output/FewShot Prompting/llama-3.3-70b-versatile/\")\n","BASE_OUT.mkdir(parents=True, exist_ok=True)\n","\n","FINAL_OUTPUT_FILE = BASE_OUT / \"llama-3.3-70b-versatile_fewshot_full_output.xlsx\"\n","\n","API_KEY_PATH = \"/content/drive/MyDrive/Final Thesis Code/api_keys/groq_key2.txt\"\n","\n","def load_key(path):\n","    with open(path) as f:\n","        return f.read().strip()\n","\n","API_KEY = load_key(API_KEY_PATH)\n","client = Groq(api_key=API_KEY)\n","\n","# ================================================================\n","# 3. GLOBAL CONFIG\n","# ================================================================\n","\n","MODEL_NAME = \"llama-3.3-70b-versatile\"\n","GLOBAL_MIN_GAP = 15\n","LAST_TS = 0.0\n","MAX_CHARS = 2600\n","\n","VALID_TOPICS = [\n","    \"Natural Language Processing\",\"Artificial Intelligence\",\"Prompt Engineering\",\n","    \"Machine Learning\",\"Deep Learning\",\"Reinforcement Learning\",\"Generative AI\",\n","    \"Data Science\",\"Time Series\",\"Statistics\",\"LangChain\",\"Langraph\",\n","    \"Python Programming\",\"Mlops\",\"Agentic AI\",\"Other\"\n","]\n","\n","# ================================================================\n","# 4. LOGGING\n","# ================================================================\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger()\n","\n","# ================================================================\n","# 5. CLEANING & CHUNKING\n","# ================================================================\n","\n","def deep_clean(t):\n","    t = str(t)\n","    t = re.sub(r\"https?://\\S+\", \" \", t)\n","    t = re.sub(r\"\\s+\", \" \", t)\n","    return t.strip()\n","\n","def chunk_text(text, max_chars=MAX_CHARS):\n","    clean = deep_clean(text)\n","    if len(clean) <= max_chars:\n","        return [clean]\n","    sents = re.split(r\"(?<=[.!?])\\s+\", clean)\n","    chunks, cur = [], \"\"\n","    for s in sents:\n","        if len(cur) + len(s) < max_chars:\n","            cur += \" \" + s\n","        else:\n","            chunks.append(cur.strip())\n","            cur = s\n","    if cur.strip(): chunks.append(cur.strip())\n","    return chunks\n","\n","# ================================================================\n","# 6. JSON EXTRACTION\n","# ================================================================\n","\n","def extract_json(txt):\n","    try:\n","        s, e = txt.find(\"{\"), txt.rfind(\"}\")\n","        if s == -1 or e == -1:\n","            return {}\n","        return json.loads(txt[s:e+1])\n","    except:\n","        return {}\n","\n","# ================================================================\n","# 7. GROQ CALL (RELIABLE)\n","# ================================================================\n","\n","def groq_call(prompt, temperature=0.2, retries=3):\n","    global LAST_TS\n","    now = time.time()\n","\n","    if LAST_TS > 0 and now - LAST_TS < GLOBAL_MIN_GAP:\n","        time.sleep(GLOBAL_MIN_GAP - (now - LAST_TS))\n","\n","    for attempt in range(retries):\n","        try:\n","            resp = client.chat.completions.create(\n","                model=MODEL_NAME,\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=temperature,\n","                max_tokens=2048\n","            )\n","            LAST_TS = time.time()\n","            return resp.choices[0].message.content\n","        except Exception as e:\n","            print(f\"Retry {attempt+1}/{retries}: {e}\")\n","            time.sleep(4)\n","\n","    return \"\"\n","\n","# ================================================================\n","# 8. FEW-SHOT TASKS\n","# ================================================================\n","\n","# ------ SUMMARY ------\n","def generate_summary(transcript):\n","    chunks = chunk_text(transcript)\n","    partial = []\n","\n","    fewshot = \"\\n\\n\".join([f\"INPUT: {x['input']}\\nOUTPUT: {x['output']}\" for x in FEWSHOT_SUMMARIES])\n","\n","    for c in chunks:\n","        prompt = f\"\"\"\n","Learn from examples:\n","{fewshot}\n","\n","Now summarise the transcript chunk.\n","Return ONLY JSON:\n","{{\"generated_summary\":\"...\"}}\n","\n","CHUNK:\n","\\\"\\\"\\\"{c}\\\"\\\"\\\"\n","\"\"\"\n","        out = groq_call(prompt, 0.15)\n","        j = extract_json(out)\n","        partial.append(j.get(\"generated_summary\", \"\"))\n","\n","    combined = \" \".join(partial)\n","\n","    final_prompt = f\"\"\"\n","Combine the drafts into a 120–160 word summary.\n","Return ONLY JSON: {{\"generated_summary\":\"...\"}}\n","\n","DRAFTS:\n","\\\"\\\"\\\"{combined}\\\"\\\"\\\"\n","\"\"\"\n","    out2 = groq_call(final_prompt, 0.15)\n","    j2 = extract_json(out2)\n","    return j2.get(\"generated_summary\", \"\")\n","\n","# ------ TOPICS ------\n","def classify_topic(transcript, summary):\n","    text = summary + \" \" + transcript[:2000]\n","\n","    examples = \"\\n\".join(\n","        [f\"INPUT: {x['input']}\\nOUTPUT: {x['output']}\" for x in FEWSHOT_TOPICS]\n","    )\n","\n","    prompt = f\"\"\"\n","Learn from examples:\n","{examples}\n","\n","Pick up to 3 topics from:\n","{', '.join(VALID_TOPICS)}\n","\n","Return JSON: {{\"predicted_topics\":[\"...\"]}}\n","\n","TEXT:\n","\\\"\\\"\\\"{text}\\\"\\\"\\\"\n","\"\"\"\n","    out = groq_call(prompt, 0.1)\n","    j = extract_json(out)\n","    topics = j.get(\"predicted_topics\", [])\n","    if isinstance(topics, str):\n","        topics = [topics]\n","\n","    cleaned = []\n","    for t in topics:\n","        for v in VALID_TOPICS:\n","            if t.lower() == v.lower():\n","                cleaned.append(v)\n","                break\n","\n","    return list(dict.fromkeys(cleaned))[:3] or [\"Other\"]\n","\n","# ------ Q&A ------\n","def generate_qa(transcript):\n","    first = chunk_text(transcript)[0]\n","    examples = \"\\n\".join([f\"Q:{x['q']}\\nA:{x['a']}\" for x in FEWSHOT_QA])\n","\n","    prompt = f\"\"\"\n","Learn QA from examples:\n","{examples}\n","\n","Return JSON: {{\"generated_questions\":[{{\"q\":\"...\",\"a\":\"...\"}}]}}\n","\n","Text:\n","\\\"\\\"\\\"{first}\\\"\\\"\\\"\n","\"\"\"\n","    out = groq_call(prompt, 0.1)\n","    j = extract_json(out)\n","    qas = j.get(\"generated_questions\", [])\n","    lines = []\n","    for qa in qas:\n","        lines.append(f\"Q: {qa.get('q','')}\")\n","        lines.append(f\"A: {qa.get('a','')}\")\n","    return \"\\n\".join(lines)\n","\n","# ------ CONCEPTS ------\n","def generate_concepts(transcript):\n","    first = chunk_text(transcript)[0]\n","    examples = \"\\n\".join([\", \".join(lst) for lst in FEWSHOT_CONCEPTS])\n","\n","    prompt = f\"\"\"\n","Learn from examples:\n","{examples}\n","\n","Extract 10–12 technical concepts.\n","Return JSON: {{\"key_concepts\":[\"...\"]}}\n","\n","Text:\n","\\\"\\\"\\\"{first}\\\"\\\"\\\"\n","\"\"\"\n","    out = groq_call(prompt, 0.15)\n","    j = extract_json(out)\n","    return \", \".join(j.get(\"key_concepts\", []))\n","\n","# ================================================================\n","# 9. MAIN PIPELINE\n","# ================================================================\n","\n","def run_pipeline():\n","    df = pd.read_excel(INPUT_FILE)\n","\n","    if FINAL_OUTPUT_FILE.exists():\n","        old = pd.read_excel(FINAL_OUTPUT_FILE)\n","        processed = set(old[\"row_index\"])\n","        results = old.to_dict(orient=\"records\")\n","        print(f\"Resuming: {len(processed)} rows already completed.\")\n","    else:\n","        processed = set()\n","        results = []\n","\n","    for idx, row in df.iterrows():\n","        if idx in processed:\n","            continue\n","\n","        title = str(row[\"title\"])\n","        transcript = str(row[\"transcript\"])\n","\n","        print(\"\\nProcessing:\", title)\n","\n","        summary = generate_summary(transcript)\n","        topics = classify_topic(transcript, summary)\n","        qa = generate_qa(transcript)\n","        concepts = generate_concepts(transcript)\n","\n","        # ----------- PRINT ALL TASK OUTPUTS TO CONSOLE -----------\n","        print(\"\\n========== OUTPUT FOR ROW\", idx, \"==========\")\n","\n","        print(\"\\nSUMMARY:\\n\")\n","        print(summary)\n","\n","        print(\"\\nTOPIC CLASSIFICATION:\\n\")\n","        print(topics)\n","\n","        print(\"\\nGENERATED Q&A:\\n\")\n","        print(qa)\n","\n","        print(\"\\nKEY CONCEPTS:\\n\")\n","        print(concepts)\n","\n","        print(\"\\n============================================\")\n","\n","        rec = {\n","            \"row_index\": idx,\n","            \"title\": title,\n","            \"summary\": summary,\n","            \"topic_classification\": \", \".join(topics),\n","            \"Q_and_A\": qa,\n","            \"key_concepts\": concepts\n","        }\n","\n","        results.append(rec)\n","        pd.DataFrame(results).to_excel(FINAL_OUTPUT_FILE, index=False)\n","\n","    return pd.DataFrame(results)\n","\n","# ================================================================\n","# 10. RUN\n","# ================================================================\n","\n","df_out = run_pipeline()\n","print(\"Few-Shot pipeline completed successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UAD0_jOtsWUG","executionInfo":{"status":"ok","timestamp":1764002586591,"user_tz":-330,"elapsed":788526,"user":{"displayName":"Sarah Smruthi","userId":"05354743683624481075"}},"outputId":"cc92e2e4-6b6f-46de-d421-3a670ab8c299"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Resuming: 23 rows already completed.\n","\n","Processing: SVD: Eigen Action Heros [Matlab]\n","\n","========== OUTPUT FOR ROW 23 ==========\n","\n","SUMMARY:\n","\n","The lecture discusses eigenfaces and singular value decomposition (SVD) for image classification. It uses examples of celebrities like Arnold Schwarzenegger, Sylvester Stallone, and Taylor Swift to demonstrate projecting images into a lower-dimensional space using SVD for clustering and classification. However, it also notes the limitations of these methods, such as sensitivity to skin tone and hair color, and suggests that advanced techniques like 3D face reconstruction can improve accuracy.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Deep Learning', 'Machine Learning']\n","\n","GENERATED Q&A:\n","\n","Q: What does attention allow models to do?\n","A: It lets models focus on the most relevant tokens in a sequence.\n","Q: Why are convolutions useful in vision?\n","A: They extract local spatial features for image classification.\n","Q: How do agents learn in reinforcement learning?\n","A: They learn by maximising cumulative rewards through trial and error.\n","Q: When is few-shot prompting effective?\n","A: When limited task-specific data exists but examples guide behaviour.\n","Q: Who typically maintains ML pipelines in production?\n","A: Machine learning engineers and DevOps teams.\n","Q: What is the primary function of recurrent neural networks?\n","A: They process sequential data, such as time series or natural language.\n","Q: How do transformers handle long-range dependencies?\n","A: They use self-attention mechanisms to weigh the importance of different input elements.\n","Q: What is the purpose of batch normalization?\n","A: It normalizes the inputs to each layer, stabilizing the training process.\n","Q: Why are pre-trained models useful?\n","A: They provide a starting point for fine-tuning on specific tasks, reducing training time and data requirements.\n","Q: What is the role of regularization in machine learning?\n","A: It prevents overfitting by adding a penalty term to the loss function, encouraging simpler models.\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: LangChain Crash Course #3 - What is LangChain?\n","\n","========== OUTPUT FOR ROW 24 ==========\n","\n","SUMMARY:\n","\n","Lang Chain is a framework that connects large language models to the real world, enabling applications to leverage their reasoning abilities with external APIs, databases, and services. This allows for complex tasks like booking flights and hotels. Lang Chain accesses external data sources, interacts with the web, and performs tasks, making AI more actionable in the real world.\n","\n","TOPIC CLASSIFICATION:\n","\n","['LangChain', 'Natural Language Processing', 'Machine Learning']\n","\n","GENERATED Q&A:\n","\n","Q: What is the primary limitation of large language models?\n","A: They cannot interact with the real world on their own.\n","Q: What is the role of Lang Chain in application development?\n","A: It acts as a bridge between large language models and the real world, enabling interaction with APIs, databases, and other external systems.\n","Q: What benefit does Lang Chain provide in terms of model switching?\n","A: It allows for easy switching between different large language models, such as replacing one model with another, without requiring changes to the application code.\n","Q: What kind of tasks can an AI powered by Lang Chain perform in the real world?\n","A: It can access various APIs, such as flight and restaurant booking APIs, to perform tasks like booking flights and hotels.\n","Q: What is the relationship between Lang Chain and large language models?\n","A: Lang Chain is a framework that enables large language models to interact with the real world, effectively extending their capabilities beyond just reasoning and processing text.\n","\n","KEY CONCEPTS:\n","\n","Large Language Models (LLMs), Chat Application, Model Framework, API Integration, Database Interaction, Real-World Interaction, Lang Chain, Application Development, Machine Learning Models, Natural Language Processing (NLP), Model Switching, Hugging Face LLM\n","\n","============================================\n","\n","Processing: How To Use Residuals For Time Series Forecasting\n","\n","========== OUTPUT FOR ROW 25 ==========\n","\n","SUMMARY:\n","\n","This video discusses residual analysis in time series forecasting, covering residuals, their analysis, and use in improving forecasting methods. Residuals are the difference between fitted and actual values, helping detect trends and inconsistencies. The video covers using Python for residual analysis, including plotting autocorrelation and partial autocorrelation functions and statistical tests like the Ljung-Box test. It also discusses diagnosing forecasting model issues using residuals, covering autocorrelation and bias, and demonstrates addressing these problems with tools like the Ljung-Box test and histogram plots.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Time Series', 'Data Science', 'Statistics']\n","\n","GENERATED Q&A:\n","\n","Q: What enables models to prioritize certain parts of the input data?\n","A: Attention mechanisms\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: \n","Build a Text-to-SQL Agent for Smarter Database Queries\n","\n","========== OUTPUT FOR ROW 26 ==========\n","\n","SUMMARY:\n","\n","The video demonstrates building an AI agent that interacts with a database using SQL knowledge from large language models. It leverages LangGraph, Next.js, and Watsonx.ai, with a frontend application and in-memory database using SQLite. The session implements a joke-telling feature and sets up a Watsonx.ai project, creating a ReAct agent and handling serialization and deserialization of message history. The speaker also sets up a SQLite database, creates a TXS SQL agent, and enhances the large language model's ability to generate SQL queries, testing its performance with simple and complex queries.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Natural Language Processing', 'Artificial Intelligence']\n","\n","GENERATED Q&A:\n","\n","Q: What is the goal of building an AI agent in this video?\n","A: To build an agent that can talk to a database using SQL knowledge.\n","Q: What tools are used to build the ReAct agent?\n","A: LangGraph, Next.js, and models running on watsonx.ai.\n","Q: What type of database is used in this project?\n","A: An in-memory database using SQLite.\n","Q: What is the purpose of using Tailwind in this project?\n","A: To avoid writing CSS code.\n","Q: What is the name of the component created in pages.tsx?\n","A: Home\n","Q: What is the purpose of the input box in the Home component?\n","A: To type a message to the large language model.\n","Q: How is the Next.js application started?\n","A: By running npm run dev.\n","\n","KEY CONCEPTS:\n","\n","Large Language Model, SQL, LangGraph, ReAct Agent, Next.js, Frontend Application, In-Memory Database, SQLite, TypeScript, Tailwind, VS Code, CLI\n","\n","============================================\n","\n","Processing: Learn Prompt Engineering from Scratch: Master the Art of Text Generation - Introduction\n","\n","========== OUTPUT FOR ROW 27 ==========\n","\n","SUMMARY:\n","\n","The course covers prompt engineering, a field within NLP that focuses on generating high-quality text outputs in response to prompts. It introduces the fundamentals, benefits, and limitations of prompt engineering, and provides a comprehensive introduction to fine-tuning pre-trained large language models, enabling students to build models that produce effective text outputs.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Natural Language Processing', 'Prompt Engineering', 'Machine Learning']\n","\n","GENERATED Q&A:\n","\n","Q: What is prompt engineering?\n","A: A specialized field within natural language processing that focuses on building models that can generate high-quality text outputs in response to prompts or input.\n","Q: Why is prompt engineering important?\n","A: It allows us to generate text outputs that are more accurate, coherent, and contextually appropriate than traditional rule-based or keyword-based approaches.\n","Q: What are the key benefits of prompt engineering?\n","A: Generating text outputs that are more accurate, coherent, and contextually appropriate, which can significantly impact user experience and engagement.\n","Q: What are the limitations of prompt engineering?\n","A: Prompt engineering models may struggle with complex and ambiguous prompts, or generate outputs that are biased and inaccurate due to underlying data or model architecture.\n","Q: What can be expected to learn from this course on prompt engineering?\n","A: A comprehensive introduction to prompt engineering, covering everything from the basics to advanced techniques of fine-tuning pre-trained large language models.\n","\n","KEY CONCEPTS:\n","\n","Prompt Engineering, Natural Language Processing, Pre-trained Large Language Models, Fine-tuning, Text Generation, Language Translation, Content Generation, Rule-based Approaches, Keyword-based Approaches, Model Architecture, Bias in AI Models, Prompt Analysis\n","\n","============================================\n","\n","Processing: Q-learning - Explained!\n","\n","========== OUTPUT FOR ROW 28 ==========\n","\n","SUMMARY:\n","\n","The session introduces Q-learning, a value-based reinforcement learning method that determines a state-action value function to maximize total rewards. It contrasts value-based and policy-based methods, discussing state value functions and the Bellman equation. Q-learning updates Q-values based on temporal difference errors, using a gradient update rule. The technique is an off-policy reinforcement learning method where an agent learns to predict expected rewards by updating a Q-table, dictating the target policy to achieve optimal rewards. A grid world example illustrates how Q-learning works to learn an optimal policy, with calculations of observed and expected Q-values.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Reinforcement Learning', 'Machine Learning', 'Artificial Intelligence']\n","\n","GENERATED Q&A:\n","\n","Q: What does attention allow models to do?\n","A: It lets models focus on the most relevant tokens in a sequence.\n","Q: Why are convolutions useful in vision?\n","A: They extract local spatial features for image classification.\n","Q: How do agents learn in reinforcement learning?\n","A: They learn by maximising cumulative rewards through trial and error.\n","Q: When is few-shot prompting effective?\n","A: When limited task-specific data exists but examples guide behaviour.\n","Q: Who typically maintains ML pipelines in production?\n","A: Machine learning engineers and DevOps teams.\n","Q: What is the primary function of recurrent neural networks?\n","A: They process sequential data, such as time series or natural language.\n","Q: How do transformers handle long-range dependencies?\n","A: They use self-attention mechanisms to weigh the importance of different input elements.\n","Q: What is the purpose of batch normalization?\n","A: It normalizes the inputs to each layer, stabilizing the training process.\n","Q: Why are pre-trained models useful?\n","A: They provide a starting point for fine-tuning on specific tasks, reducing training time and data requirements.\n","Q: What is the role of regularization in machine learning?\n","A: It prevents overfitting by adding a penalty term to the loss function, encouraging simpler models.\n","\n","KEY CONCEPTS:\n","\n","Self-Attention Mechanism, Query-Key-Value, Positional Encoding, Convolutional Layer, Pooling Operation, Feature Map, Reward Function, Policy Gradient, Q-Learning, Few-Shot Prompting, Chain-of-Thought Reasoning, Instruction Tuning\n","\n","============================================\n","\n","Processing: Training Your Logistic Classifier\n","\n","========== OUTPUT FOR ROW 29 ==========\n","\n","SUMMARY:\n","\n","This lecture introduces logistic classification, explaining how linear functions generate predictions through matrix multiplication. It covers the role of weights, bias, and the softmax function in turning scores into probabilities for classification tasks, providing a foundation for understanding logistic classification.\n","\n","TOPIC CLASSIFICATION:\n","\n","['Machine Learning', 'Deep Learning']\n","\n","GENERATED Q&A:\n","\n","Q: What type of classifier is a logistic classifier?\n","A: A linear classifier\n","Q: How does a logistic classifier generate its predictions?\n","A: By applying a linear function to the inputs, which is a giant matrix multiply\n","Q: What are the components of the linear function in a logistic classifier?\n","A: The inputs (X), the weights (W), and the bias term (b)\n","Q: What is the goal of training a logistic classifier?\n","A: To find the values for the weights and bias that are good at performing predictions\n","Q: How are scores turned into probabilities in a logistic classifier?\n","A: By using a softmax function\n","Q: What are the properties of proper probabilities produced by the softmax function?\n","A: They sum to 1, are large when the scores are large, and small when the scores are comparatively smaller\n","\n","KEY CONCEPTS:\n","\n","Logistic Classifier, Linear Classifier, Linear Function, Matrix Multiply, Machine Learning, Model Training, Weights, Bias, Scores, Softmax Function, Logits, Probabilities\n","\n","============================================\n","Few-Shot pipeline completed successfully!\n"]}]},{"cell_type":"code","source":["#####################################################################\n","# 1. IMPORTS\n","#####################################################################\n","import os, re, json, warnings\n","import pandas as pd\n","import numpy as np\n","\n","from rouge_score import rouge_scorer\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from bert_score import score as bert_score\n","\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","\n","#####################################################################\n","# 2. SUPPRESS WARNINGS (BERTScore spam)\n","#####################################################################\n","warnings.filterwarnings(\"ignore\")\n","import logging\n","logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n","logging.getLogger(\"absl\").setLevel(logging.ERROR)\n","\n","\n","#####################################################################\n","# 3. PATHS (EDIT THESE)\n","#####################################################################\n","INPUT_FILE = \"/content/drive/MyDrive/Final Thesis Code/Input/clean_input_30.xlsx\"\n","OUTPUT_FILE = \"/content/drive/MyDrive/Final Thesis Code/Output/FewShot Prompting/llama-3.3-70b-versatile/llama-3.3-70b-versatile_fewshot_full_output.xlsx\"\n","FINAL_EVAL_JSON = \"/content/drive/MyDrive/Final Thesis Code/Output/FewShot Prompting/llama-3.3-70b-versatile/evaluation_final.json\"\n","\n","print(\"Loaded input:\", INPUT_FILE)\n","print(\"Loaded model output:\", OUTPUT_FILE)\n","\n","\n","#####################################################################\n","# 4. GOLD TOPIC EXTRACTION (KEYWORD-BASED — FINAL VERSION)\n","#####################################################################\n","def gold_topics_from_ref_summary(ref_sum: str):\n","    text = (ref_sum or \"\").lower()\n","    matched = []\n","\n","    rules = [\n","        (\"Natural Language Processing\", [\n","            \"nlp\", \"bert\", \"transformer\", \"language model\", \"token\",\n","            \"text processing\", \"semantic\", \"embedding\"\n","        ]),\n","        (\"Artificial Intelligence\", [\n","            \"artificial intelligence\", \"ai system\", \"symbolic ai\",\n","            \"reasoning\", \"planning\", \"search\"\n","        ]),\n","        (\"Prompt Engineering\", [\n","            \"prompt\", \"few-shot\", \"zero-shot\", \"instruction\",\n","            \"cot\", \"chain-of-thought\", \"in-context learning\"\n","        ]),\n","        (\"Machine Learning\", [\n","            \"machine learning\", \"supervised\", \"unsupervised\", \"regression\",\n","            \"classification\", \"clustering\", \"features\"\n","        ]),\n","        (\"Deep Learning\", [\n","            \"deep learning\", \"neural network\", \"cnn\", \"rnn\",\n","            \"lstm\", \"gan\", \"transformer model\", \"backpropagation\"\n","        ]),\n","        (\"Reinforcement Learning\", [\n","            \"reinforcement\", \"policy gradient\", \"q-learning\",\n","            \"reward\", \"actor-critic\", \"rlhf\"\n","        ]),\n","        (\"Generative AI\", [\n","            \"genai\", \"text generation\", \"image generation\",\n","            \"diffusion\", \"sampling\", \"generation model\", \"llm\"\n","        ]),\n","        (\"Data Science\", [\n","            \"data science\", \"visualization\", \"feature\", \"pandas\",\n","            \"analysis\", \"data preprocessing\", \"eda\"\n","        ]),\n","        (\"Time Series\", [\n","            \"time series\", \"forecasting\", \"temporal\", \"trend\",\n","            \"seasonality\", \"arima\", \"prophet\", \"lag\"\n","        ]),\n","        (\"Statistics\", [\n","            \"statistics\", \"probability\", \"distribution\", \"variance\",\n","            \"hypothesis\", \"confidence interval\", \"p-value\"\n","        ]),\n","        (\"LangChain\", [\n","            \"langchain\", \"chain\", \"memory\", \"retriever\",\n","            \"agent executor\", \"llmchain\", \"prompt template\"\n","        ]),\n","        (\"Langraph\", [\n","            \"langraph\", \"workflow\", \"graph\", \"multi-agent orchestration\",\n","            \"node\", \"edge\", \"state graph\"\n","        ]),\n","        (\"Python Programming\", [\n","            \"python\", \"numpy\", \"matplotlib\", \"function\",\n","            \"loop\", \"list comprehension\", \"script\"\n","        ]),\n","        (\"Mlops\", [\n","            \"mlops\", \"deployment\", \"monitoring\", \"pipeline\",\n","            \"model registry\", \"cicd\", \"serving\"\n","        ]),\n","        (\"Agentic AI\", [\n","            \"agentic\", \"tool calling\", \"multi-agent\",\n","            \"planner\", \"agent\", \"reasoning agent\", \"autonomous\"\n","        ])\n","    ]\n","\n","    for label, keywords in rules:\n","        if any(kw in text for kw in keywords):\n","            matched.append(label)\n","\n","    return matched or [\"Other\"]\n","\n","\n","#####################################################################\n","# 5. TOKENIZER FOR QA & CONCEPTS\n","#####################################################################\n","STOPWORDS = set([\n","    \"the\",\"a\",\"an\",\"in\",\"on\",\"for\",\"to\",\"and\",\"or\",\"of\",\"with\",\"as\",\n","    \"by\",\"at\",\"from\",\"that\",\"this\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\n","    \"it\",\"its\",\"into\",\"about\",\"over\",\"under\",\"between\",\"across\",\n","    \"through\",\"their\",\"they\",\"you\",\"your\",\"we\",\"our\"\n","])\n","\n","def tokenize(text: str):\n","    return [\n","        t for t in re.findall(r\"[A-Za-z][A-Za-z0-9\\-_\\’']+\", text.lower())\n","        if t not in STOPWORDS\n","    ]\n","\n","\n","#####################################################################\n","# 6. FINAL EVALUATION FUNCTION  (FULL AND CORRECT)\n","#####################################################################\n","def evaluate(df_out: pd.DataFrame, df_ref: pd.DataFrame):\n","\n","    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n","    smooth = SmoothingFunction().method1\n","\n","    sum_r, sum_b, sum_bert = [], [], []\n","    overlap_acc_list, jaccard_list, micro_f1_list = [], [], []\n","    macro_f1_list, weighted_f1_list = [], []\n","    qa_bleu, qa_div, qa_ans = [], [], []\n","    kc_p, kc_r, kc_f = [], [], []\n","\n","    VALID_TOPICS = [\n","        \"Natural Language Processing\", \"Artificial Intelligence\", \"Prompt Engineering\",\n","        \"Machine Learning\", \"Deep Learning\", \"Reinforcement Learning\", \"Generative AI\",\n","        \"Data Science\", \"Time Series\", \"Statistics\", \"LangChain\", \"Langraph\",\n","        \"Python Programming\", \"Mlops\", \"Agentic AI\", \"Other\"\n","    ]\n","\n","    # for macro/weighted F1\n","    all_true, all_pred = [], []\n","\n","    for _, row in df_out.iterrows():\n","        idx = int(row[\"row_index\"])\n","        ref_summary = df_ref.loc[idx, \"Reference Summary\"] or \"\"\n","\n","        # -------------------- Summarisation --------------------\n","        gen_sum = row[\"summary\"] or \"\"\n","        r = rouge.score(ref_summary, gen_sum)['rougeL'].fmeasure\n","        b = sentence_bleu([ref_summary.split()], gen_sum.split(), smoothing_function=smooth)\n","\n","        with warnings.catch_warnings():\n","            warnings.simplefilter(\"ignore\")\n","            P, R, F1 = bert_score([gen_sum], [ref_summary], lang='en', verbose=False)\n","\n","        sum_r.append(r)\n","        sum_b.append(b)\n","        sum_bert.append(float(F1.mean()))\n","\n","        # -------------------- Topic Classification --------------------\n","        gold = gold_topics_from_ref_summary(ref_summary)\n","        pred = [x.strip() for x in (row[\"topic_classification\"] or \"\").split(\",\") if x.strip()]\n","\n","        set_pred = set(pred)\n","        set_gold = set(gold)\n","\n","        # Overlap Accuracy (your metric)\n","        overlap_acc = 1.0 if len(set_pred & set_gold) > 0 else 0.0\n","\n","        # Jaccard\n","        inter = len(set_pred & set_gold)\n","        union = len(set_pred | set_gold)\n","        jaccard = inter / union if union > 0 else 0.0\n","\n","        # Micro-F1\n","        tp = inter\n","        fp = len([p for p in pred if p not in gold])\n","        fn = len([g for g in gold if g not in pred])\n","\n","        prec = tp / (tp + fp) if (tp + fp) else 0.0\n","        rec  = tp / (tp + fn) if (tp + fn) else 0.0\n","        micro_f1 = (2 * prec * rec / (prec + rec)) if (prec + rec) else 0.0\n","\n","        overlap_acc_list.append(overlap_acc)\n","        jaccard_list.append(jaccard)\n","        micro_f1_list.append(micro_f1)\n","\n","        # Macro/Weighted F1 prep\n","        true_bin = [1 if t in gold else 0 for t in VALID_TOPICS]\n","        pred_bin = [1 if t in pred else 0 for t in VALID_TOPICS]\n","\n","        all_true.append(true_bin)\n","        all_pred.append(pred_bin)\n","\n","        # -------------------- Q&A --------------------\n","        qa_text = row[\"Q_and_A\"] or \"\"\n","        qs = [l[2:].strip() for l in qa_text.splitlines() if l.lower().startswith(\"q:\")]\n","\n","        gold_qs = [\n","            \"What is the main topic discussed in the video?\",\n","            \"Why is this topic important?\",\n","            \"How is the core concept explained?\",\n","            \"What example is mentioned in the content?\",\n","            \"What is the key conclusion of the video?\"\n","        ]\n","\n","        if qs:\n","            bleu_vals = [\n","                sentence_bleu([g.split()], q.split(), smoothing_function=smooth)\n","                for g in gold_qs for q in qs\n","            ]\n","            qa_bleu.append(np.mean(bleu_vals))\n","        else:\n","            qa_bleu.append(0.0)\n","\n","        toks = [t for q in qs for t in q.split()]\n","        qa_div.append(len(set(toks)) / len(toks) if toks else 0.0)\n","\n","        ref_tokens = set(tokenize(ref_summary))\n","        ans_count = sum(\n","            1 for q in qs\n","            if len(set(tokenize(q)) & ref_tokens) / max(1, len(tokenize(q))) >= 0.3\n","        )\n","        qa_ans.append(ans_count / len(qs) if qs else 0.0)\n","\n","        # -------------------- Key Concepts --------------------\n","        kc_text = str(row.get(\"key_concepts\", \"\") or \"\")\n","        pred_concepts = [c.strip().lower() for c in kc_text.split(\",\") if c.strip()]\n","\n","        ref_concepts = tokenize(ref_summary)\n","        ref_top = ref_concepts[:25]\n","\n","        tp_kc = len([p for p in pred_concepts[:10] if any(p in r or r in p for r in ref_top)])\n","\n","        p_val = tp_kc / 10\n","        r_val = tp_kc / len(ref_top) if ref_top else 0\n","        f1_val = (2*p_val*r_val/(p_val+r_val)) if (p_val+r_val) else 0\n","\n","        kc_p.append(p_val)\n","        kc_r.append(r_val)\n","        kc_f.append(f1_val)\n","\n","    # Compute macro/weighted F1\n","    all_true = np.array(all_true)\n","    all_pred = np.array(all_pred)\n","\n","    macro_f1 = precision_recall_fscore_support(all_true, all_pred, average=\"macro\", zero_division=0)[2]\n","    weighted_f1 = precision_recall_fscore_support(all_true, all_pred, average=\"weighted\", zero_division=0)[2]\n","\n","    return {\n","        \"Summarisation\": {\n","            \"ROUGE-L F1\": float(np.mean(sum_r)),\n","            \"BLEU\": float(np.mean(sum_b)),\n","            \"BERTScore F1\": float(np.mean(sum_bert))\n","        },\n","        \"Topic Classification\": {\n","            \"Overlap Accuracy\": float(np.mean(overlap_acc_list)),\n","            \"Jaccard Index\": float(np.mean(jaccard_list)),\n","            \"Micro F1\": float(np.mean(micro_f1_list)),\n","            \"Macro F1\": float(macro_f1),\n","            \"Weighted F1\": float(weighted_f1)\n","        },\n","        \"Q&A Generation\": {\n","            \"BLEU\": float(np.mean(qa_bleu)),\n","            \"Diversity\": float(np.mean(qa_div)),\n","            \"Answerability\": float(np.mean(qa_ans))\n","        },\n","        \"Key Concept Extraction\": {\n","            \"Precision@10\": float(np.mean(kc_p)),\n","            \"Recall@10\": float(np.mean(kc_r)),\n","            \"F1@10\": float(np.mean(kc_f))\n","        }\n","    }\n","\n","\n","#####################################################################\n","# 7. RUN EVALUATION\n","#####################################################################\n","df_ref = pd.read_excel(INPUT_FILE)\n","df_out = pd.read_excel(OUTPUT_FILE)\n","\n","eval_summary = evaluate(df_out, df_ref)\n","\n","print(\"\\n==================== FINAL EVALUATION METRICS ====================\")\n","for task, vals in eval_summary.items():\n","    print(f\"\\n{task}:\")\n","    for metric, value in vals.items():\n","        print(f\"  - {metric}: {value:.4f}\")\n","\n","with open(FINAL_EVAL_JSON, \"w\") as f:\n","    json.dump(eval_summary, f, indent=2)\n","\n","print(\"\\nSaved corrected evaluation JSON to:\", FINAL_EVAL_JSON)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":695,"referenced_widgets":["ab0150d39e5a43dc9302a3206ab80832","f1fe84687f084b2493d07f82e6fc00d7","3e6ce6f9ebba4147beffd29ea224321a","6b8d5c2ab76d4a2a86010727b85ca48e","feef7f71153a49e3abee5b6b3dd85cc5","7879e7f978bc45b78c34b998d6c579b5","f13c80ad882c49cc9958e2bfe8f6a192","735588005cc346fe8066044788b82a1f","1561822b787f43738dcfeae13978b734","588341156b3d47b6b1b77b137d4d63f3","a2ae6800bb704f9ba93b96929c6d7945","a5f893c763c8435a8a4b29211f715eee","a923aece203845a3853a0238a6cb7c44","d80a4f8d045140a4be5a5e20ceee2e94","409f33eea48648098b03f18e5b3a9aa8","ceb93ae2273845429676edf13638d72d","e2f8360fdfd048728df4c38495bab86e","e1f33d6f85164240accc900306465554","16fb905754ce462e85ec06be9adc3443","9c591babe63d4af3992cf7672b871862","e829ff2ace094e709a0f09dc364ee967","714c6954dfac45c3b375bf9fde51b465","dc356d9e2e8b45799b4a6197e3c350c2","3b1e4bfd1ab24d62afd69588a98499dc","52d55767789844b48346eb7e721a2a9f","5989b894f64d48e1a72dcf974ebf7284","eab0f394cc074f03bbd9eb95342d9788","23041bfccf534909ac23035193510097","6dd716e57c3a4108bc97d71ae42f34b4","aed0af2f312143eeaf7f5fa1d5a4757f","43a118314be94a70bc5243f698e6a214","64a7563d4c7d40728a9e59df5f2a68e8","8b4828a689434491acd70db5ec0f043a","d0365b07c1ec4ae1a54ae44f23098f0c","441dc11aa15a4bf9bc30ca0a894186a1","965f483fdc764efb8e7df72a1ce2caf0","4461f67acafc4ce5bdfbea1f95de5afd","0d80af6955ec42dfab6bf509ee51c62c","f3d0001bc4fe4cbcb0e9f830d0470a58","2a89c010af88451babed02374e8101e4","bfd0f3a67dc7446fa1834e46c95f4d96","b0f3d9f1a66848918c5ef498c9bb1fc3","505cd980f73e44a5a74ef93a80966223","d78f9875b3a1492e93721763b123e05f","e242db7ed5da421ca3d90396ac77e3ca","003562768589442e95207c6f08167af0","fc78284f3f874cf5aee73b2e792d2f4a","c429b0651ee4459a8b7e6ae743d3b957","cdcc15c1389c4020887778f8f8907884","42bec8601bf64176b85922861f10c287","ad5faf705b9242f18d611bef4049039b","947b8d07dd9342e980701446c56e576b","d4ff24e857514bcea87484b7f6b3f447","87ede068bbd3466e96a80e392887c6a4","82821551885341159d73269afa4fde28","8183d39242d34c9183279d1c77c2f395","cdb7d9fa68004247ae1f7752f696fd63","0781fa940a7e4412abe1daa7cfc8a40d","fcf0d646c9c14e4fa3d3a17863efbb2b","7f984c5719b34decb3f9ea85c52a3c76","5da51e88fb7149cea2e88afaaaf08a7c","41a12a4157ad46248c30f944213c8cdd","9a7226c89f1b4f6498e02f8ae393b717","645dc5e5deac4562a3024f86b4752c0f","26868b04f0f64a27ba19076a659cdbbf","6758c4e650364296b54c7d6f1662e364"]},"id":"PwFSSN4sgQHE","executionInfo":{"status":"ok","timestamp":1764004010855,"user_tz":-330,"elapsed":166517,"user":{"displayName":"Sarah Smruthi","userId":"05354743683624481075"}},"outputId":"e815516d-bb8d-42b0-9859-916762aac85b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded input: /content/drive/MyDrive/Final Thesis Code/Input/clean_input_30.xlsx\n","Loaded model output: /content/drive/MyDrive/Final Thesis Code/Output/FewShot Prompting/llama-3.3-70b-versatile/llama-3.3-70b-versatile_fewshot_full_output.xlsx\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab0150d39e5a43dc9302a3206ab80832"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5f893c763c8435a8a4b29211f715eee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc356d9e2e8b45799b4a6197e3c350c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0365b07c1ec4ae1a54ae44f23098f0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e242db7ed5da421ca3d90396ac77e3ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8183d39242d34c9183279d1c77c2f395"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","==================== FINAL EVALUATION METRICS ====================\n","\n","Summarisation:\n","  - ROUGE-L F1: 0.2488\n","  - BLEU: 0.0296\n","  - BERTScore F1: 0.8792\n","\n","Topic Classification:\n","  - Overlap Accuracy: 0.9333\n","  - Jaccard Index: 0.3866\n","  - Micro F1: 0.5039\n","  - Macro F1: 0.4331\n","  - Weighted F1: 0.4505\n","\n","Q&A Generation:\n","  - BLEU: 0.0384\n","  - Diversity: 0.7898\n","  - Answerability: 0.4999\n","\n","Key Concept Extraction:\n","  - Precision@10: 0.3000\n","  - Recall@10: 0.1200\n","  - F1@10: 0.1714\n","\n","Saved corrected evaluation JSON to: /content/drive/MyDrive/Final Thesis Code/Output/FewShot Prompting/llama-3.3-70b-versatile/evaluation_final.json\n"]}]}]}