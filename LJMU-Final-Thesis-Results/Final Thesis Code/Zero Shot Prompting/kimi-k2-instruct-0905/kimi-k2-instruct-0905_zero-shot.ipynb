{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6VP3F5wo2fNpTZqv44jKu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMGauZ30j_V8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763911266917,"user_tz":-330,"elapsed":37437,"user":{"displayName":"Sarah Smruthi","userId":"05354743683624481075"}},"outputId":"d5ec2299-5f54-451c-a395-e55a6e40b448"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting groq\n","  Downloading groq-0.36.0-py3-none-any.whl.metadata (16 kB)\n","Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting bert-score\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.0.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.9.0+cu126)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.2.2)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.57.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.32.4)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert-score) (25.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.20.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.13.3)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.5.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.36.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (6.0.3)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.7.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2.5.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.2.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\n","Downloading groq-0.36.0-py3-none-any.whl (137 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.3/137.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=29029d43e5c5d2aa80c60233adeb6933d0a48b862472038776bab7678b1ee3e9\n","  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n","Successfully built rouge-score\n","Installing collected packages: rouge-score, groq, bert-score\n","Successfully installed bert-score-0.3.13 groq-0.36.0 rouge-score-0.1.2\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["!pip install groq rouge-score bert-score nltk\n","import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","source":["%%javascript\n","function ClickConnect(){\n","  console.log(\"Clicking\");\n","  document.querySelector(\"colab-toolbar-button#connect\").click();\n","}\n","setInterval(ClickConnect, 60000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"2fn_psYPojdv","executionInfo":{"status":"ok","timestamp":1763911266939,"user_tz":-330,"elapsed":19,"user":{"displayName":"Sarah Smruthi","userId":"05354743683624481075"}},"outputId":"9371492f-6187-4c64-d88b-ed4f52463a14"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["function ClickConnect(){\n","  console.log(\"Clicking\");\n","  document.querySelector(\"colab-toolbar-button#connect\").click();\n","}\n","setInterval(ClickConnect, 60000)\n"]},"metadata":{}}]},{"cell_type":"code","source":["#####################################################################\n","# 1. MOUNT DRIVE & IMPORTS\n","#####################################################################\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","import os, re, json, time, logging\n","from datetime import datetime\n","from pathlib import Path\n","from typing import List, Dict, Any\n","\n","import pandas as pd\n","import numpy as np\n","from groq import Groq   # Groq client\n","\n","\n","#####################################################################\n","# 2. PATHS & API KEY\n","#####################################################################\n","INPUT_FILE = \"/content/drive/MyDrive/Final Thesis Code/Input/clean_input_30.xlsx\"\n","\n","BASE_OUT = Path(\"/content/drive/MyDrive/Final Thesis Code/Output/Zero Shot Prompting/kimi-k2-instruct-0905/\")\n","BASE_OUT.mkdir(parents=True, exist_ok=True)\n","\n","FINAL_OUTPUT_FILE = BASE_OUT / \"kimi-k2-instruct-0905_zero_shot_full_output.xlsx\"\n","\n","API_KEY_PATH = \"/content/drive/MyDrive/Final Thesis Code/api_keys/groq_key4.txt\"\n","\n","def load_key(path: str):\n","    with open(path, \"r\") as f:\n","        return f.read().strip()\n","\n","API_KEY = load_key(API_KEY_PATH)\n","client = Groq(api_key=API_KEY)\n","\n","print(\"Input:\", INPUT_FILE)\n","print(\"Output folder:\", BASE_OUT)\n","print(\"Groq API key loaded ✓\")\n","\n","\n","#####################################################################\n","# 3. GLOBAL CONFIG\n","#####################################################################\n","MODEL_NAME     = \"moonshotai/kimi-k2-instruct-0905\"\n","MAX_CHARS      = 2300\n","GLOBAL_MIN_GAP = 45   # Groq is faster, but we keep a safety gap\n","LAST_TS        = 0.0\n","\n","VALID_TOPICS = [\n","    \"Natural Language Processing\",\"Artificial Intelligence\",\"Prompt Engineering\",\n","    \"Machine Learning\",\"Deep Learning\",\"Reinforcement Learning\",\"Generative AI\",\n","    \"Data Science\",\"Time Series\",\"Statistics\",\"LangChain\",\"Langraph\",\n","    \"Python Programming\",\"Mlops\",\"Agentic AI\",\"Other\"\n","]\n","\n","\n","#####################################################################\n","# 4. LOGGING\n","#####################################################################\n","def setup_logging():\n","    logs = Path(\"/content/logs\")\n","    logs.mkdir(exist_ok=True)\n","    logfile = logs / f\"log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n","\n","    logging.basicConfig(\n","        level=logging.INFO,\n","        handlers=[logging.FileHandler(logfile, encoding=\"utf-8\"),\n","                  logging.StreamHandler()],\n","        format=\"%(asctime)s | %(levelname)s | %(message)s\"\n","    )\n","    return logging.getLogger(__name__)\n","\n","logger = setup_logging()\n","\n","\n","#####################################################################\n","# 5. CLEANING & CHUNKING\n","#####################################################################\n","def deep_clean(text: str) -> str:\n","    t = str(text)\n","    t = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", t)\n","    t = re.sub(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \" \", t)\n","    t = re.sub(r\"\\[.*?\\]|\\(.*?\\)\", \" \", t)\n","    t = re.sub(r\"\\s+\", \" \", t)\n","\n","    t = re.sub(r\"\\bNLP\\b\", \"Natural Language Processing (NLP)\", t)\n","    t = re.sub(r\"\\bML\\b\", \"Machine Learning (ML)\", t)\n","    t = re.sub(r\"\\bAI\\b\", \"Artificial Intelligence (AI)\", t)\n","    return t.strip()\n","\n","\n","def chunk_text(text: str, max_chars=MAX_CHARS) -> List[str]:\n","    clean = deep_clean(text)\n","    if len(clean) <= max_chars:\n","        return [clean] if clean else [\"\"]\n","\n","    sents = [s.strip() for s in re.split(r\"(?<=[.!?])\\s+\", clean) if s.strip()]\n","    chunks, cur = [], \"\"\n","\n","    for s in sents:\n","        if len(cur) + len(s) + 1 <= max_chars:\n","            cur = (cur + \" \" + s).strip()\n","        else:\n","            if cur:\n","                chunks.append(cur)\n","            cur = s\n","\n","    if cur:\n","        chunks.append(cur)\n","    return chunks or [\"\"]\n","\n","\n","#####################################################################\n","# 6. JSON EXTRACTION\n","#####################################################################\n","def extract_json(text: str) -> Dict[str, Any]:\n","    if not text:\n","        return {}\n","    start = text.find(\"{\")\n","    end = text.rfind(\"}\")\n","    if start == -1 or end == -1 or end <= start:\n","        return {}\n","    try:\n","        return json.loads(text[start:end+1])\n","    except:\n","        return {}\n","\n","\n","#####################################################################\n","# 7. GROQ CALL (GLOBAL WAIT + RETRIES)\n","#####################################################################\n","def groq_call(prompt: str, temperature=0.15, retries=3) -> str:\n","    global LAST_TS\n","    now = time.time()\n","\n","    if LAST_TS > 0 and now - LAST_TS < GLOBAL_MIN_GAP:\n","        wait = GLOBAL_MIN_GAP - (now - LAST_TS)\n","        logger.info(f\"Waiting {wait:.1f}s before next request\")\n","        time.sleep(wait)\n","\n","    for attempt in range(1, retries+1):\n","        try:\n","            resp = client.chat.completions.create(\n","                model=MODEL_NAME,\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=temperature,\n","                max_tokens=2048\n","            )\n","            LAST_TS = time.time()\n","            return resp.choices[0].message.content.strip()\n","\n","        except Exception as e:\n","            logger.warning(f\"Groq call failed ({attempt}/{retries}): {e}\")\n","            time.sleep(4 * attempt)\n","\n","    logger.error(\"Groq failed after retries — returning empty string.\")\n","    return \"\"\n","\n","\n","#####################################################################\n","# 8. ZERO-SHOT PROMPT (ALL TASKS IN ONE CALL)\n","#####################################################################\n","def generate_zero_shot(transcript: str):\n","    topics_short = \", \".join(VALID_TOPICS)\n","\n","    prompt = (\n","        \"You are an expert NLP assistant.\\n\"\n","        \"Perform ALL tasks concisely using ONLY the transcript.\\n\\n\"\n","        \"Respond in a JSON-like object with EXACTLY these keys:\\n\"\n","        \"generated_summary, predicted_topics, generated_questions, key_concepts.\\n\\n\"\n","        \"Requirements:\\n\"\n","        \"- generated_summary: 3–5 sentence abstractive summary.\\n\"\n","        f\"- predicted_topics: 1–3 most relevant from [{topics_short}]. Use exact labels.\\n\"\n","        \"- generated_questions: 3 short Q&A pairs with keys q and a.\\n\"\n","        \"- key_concepts: 6–10 short noun phrases, no duplicates.\\n\"\n","        \"- No explanations outside the JSON.\\n\\n\"\n","        f\"Transcript:\\n\\\"\\\"\\\"{transcript}\\\"\\\"\\\"\"\n","    )\n","\n","    out = groq_call(prompt, temperature=0.15)\n","    j = extract_json(out)\n","\n","    summary = j.get(\"generated_summary\", \"\").strip()\n","\n","    topics = j.get(\"predicted_topics\", [])\n","    if isinstance(topics, str):\n","        topics = [topics]\n","    topics = [t for t in topics if t in VALID_TOPICS] or [\"Other\"]\n","\n","    qas = j.get(\"generated_questions\", [])\n","    qa_lines = []\n","    if isinstance(qas, list):\n","        for qa in qas:\n","            q = qa.get(\"q\", \"\").strip()\n","            a = qa.get(\"a\", \"\").strip()\n","            if q: qa_lines.append(f\"Q: {q}\")\n","            if a: qa_lines.append(f\"A: {a}\")\n","\n","    concepts = j.get(\"key_concepts\", [])\n","    if not isinstance(concepts, list):\n","        concepts = []\n","    concepts = \", \".join([c.strip() for c in concepts if c.strip()])\n","\n","    return summary, topics, \"\\n\".join(qa_lines), concepts\n","\n","\n","#####################################################################\n","# 9. MAIN PIPELINE — ZERO SHOT (NO EVALUATION)\n","#####################################################################\n","def run_pipeline() -> pd.DataFrame:\n","    df = pd.read_excel(INPUT_FILE)\n","    results = []\n","\n","    if FINAL_OUTPUT_FILE.exists():\n","        old = pd.read_excel(FINAL_OUTPUT_FILE)\n","        if \"row_index\" in old.columns:\n","            done = set(old[\"row_index\"])\n","            results = old.to_dict(orient=\"records\")\n","            print(f\"Resuming — {len(done)} rows already processed.\")\n","        else:\n","            done = set()\n","    else:\n","        done = set()\n","\n","    for idx, row in df.iterrows():\n","        if idx in done:\n","            print(f\"Skipping row {idx}\")\n","            continue\n","\n","        title = str(row.get(\"title\", \"\")).strip()\n","        transcript = str(row.get(\"transcript\", \"\")).strip()\n","\n","        print(\"\\n\" + \"=\"*80)\n","        print(f\"PROCESSING ROW {idx}: {title}\")\n","        print(\"=\"*80)\n","\n","        try:\n","            summary, topics, qa_text, concepts = generate_zero_shot(transcript)\n","        except Exception as e:\n","            logger.error(f\"Error on row {idx}: {e}\")\n","            summary, topics, qa_text, concepts = \"\", [\"Other\"], \"\", \"\"\n","\n","        print(\"\\nSUMMARY:\\n\", summary)\n","        print(\"\\nTOPICS:\\n\", topics)\n","        print(\"\\nQ&A:\\n\", qa_text)\n","        print(\"\\nKEY CONCEPTS:\\n\", concepts)\n","\n","        rec = {\n","            \"row_index\": idx,\n","            \"title\": title,\n","            \"summary\": summary,\n","            \"topic_classification\": \", \".join(topics),\n","            \"Q_and_A\": qa_text,\n","            \"key_concepts\": concepts\n","        }\n","\n","        results.append(rec)\n","        pd.DataFrame(results).to_excel(FINAL_OUTPUT_FILE, index=False)\n","        print(f\"Saved row {idx}\")\n","\n","    df_out = pd.DataFrame(results)\n","    df_out.to_excel(FINAL_OUTPUT_FILE, index=False)\n","    print(\"DONE. Final file:\", FINAL_OUTPUT_FILE)\n","    return df_out\n","\n","\n","#####################################################################\n","# 10. RUN\n","#####################################################################\n","df_out = run_pipeline()\n","print(\"\\nZero-shot Groq pipeline completed ✓\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43iNTW79ojjN","executionInfo":{"status":"ok","timestamp":1763912638768,"user_tz":-330,"elapsed":1371542,"user":{"displayName":"Sarah Smruthi","userId":"05354743683624481075"}},"outputId":"0b7ab694-827c-4004-eef5-799069174b22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Input: /content/drive/MyDrive/Final Thesis Code/Input/clean_input_30.xlsx\n","Output folder: /content/drive/MyDrive/Final Thesis Code/Output/Zero Shot Prompting/kimi-k2-instruct-0905\n","Groq API key loaded ✓\n","\n","================================================================================\n","PROCESSING ROW 0: Reinforcement Learning through Human Feedback - EXPLAINED! | RLHF\n","================================================================================\n","\n","SUMMARY:\n"," The video explains reinforcement learning with human feedback (RLHF) using a grid-world agent named Frank, showing how human guidance speeds learning. It details RLHF’s two-step use in ChatGPT: first training a reward model to score answers, then using those scores with proximal policy optimization to fine-tune the model. The approach improves response quality and aligns the system with human preferences.\n","\n","TOPICS:\n"," ['Reinforcement Learning', 'Natural Language Processing', 'Generative AI']\n","\n","Q&A:\n"," Q: Which algorithms work with human feedback?\n","A: All listed: Q-learning, DQ-learning, and PPO.\n","Q: How does human feedback affect Frank’s learning?\n","A: It accelerates the learning process.\n","Q: What is the reward model’s role in ChatGPT?\n","A: To assess and score answer quality.\n","\n","KEY CONCEPTS:\n"," reinforcement learning with human feedback, reward model, proximal policy optimization, grid-world environment, ChatGPT fine-tuning, answer scoring, human ranking, iterative training, policy updates, alignment with human preferences\n","Saved row 0\n","\n","================================================================================\n","PROCESSING ROW 1: Soft Margin SVM and Kernels with CVXOPT - Practical Machine Learning Tutorial with Python p.32\n","================================================================================\n","\n","SUMMARY:\n"," The tutorial demonstrates CVXOPT-based SVM code to visualize how kernels and soft margins affect classification. It walks through linear, polynomial and RBF kernels, shows quadratic-programming formulation, and generates separable, non-separable and overlapping datasets to compare hard-margin, kernel and soft-margin results.\n","\n","TOPICS:\n"," ['Machine Learning', 'Python Programming', 'Statistics']\n","\n","Q&A:\n"," Q: What solver is used to optimize the SVM quadratic program?\n","A: CVXOPT\n","Q: Which kernel is swapped in for the nonlinear demo?\n","A: Polynomial kernel\n","Q: How is a soft-margin SVM created in the code?\n","A: Set C to a penalty value instead of None\n","\n","KEY CONCEPTS:\n"," CVXOPT quadratic solver, kernel functions, support vectors, hard vs soft margin, polynomial kernel, Gaussian RBF kernel, hyperplane visualization, quadratic programming constraints\n","Saved row 1\n","\n","================================================================================\n","PROCESSING ROW 2: How to create high-quality outputs with ChatGPT Prompt Engineering | Unlocking the Power of Prompts\n","================================================================================\n","\n","SUMMARY:\n"," Prompts are the inputs that guide large language models to produce desired outputs, and their clarity directly affects response quality. The video introduces seven prompt types—such as question, statement, and constrained prompts—and emphasizes key features like length, language, context, and constraints. Examples show how adding constraints (e.g., “one-word answer” or “500 words”) refines model outputs, and deconstructing prompts reveals their requirements and constraints.\n","\n","TOPICS:\n"," ['Prompt Engineering', 'Natural Language Processing', 'Generative AI']\n","\n","Q&A:\n"," Q: What are the seven types of prompts mentioned?\n","A: Question, statement, multiple-input, and constraint-based prompts (plus three unnamed).\n","Q: How does adding ‘one-word answer’ change the model’s response?\n","A: It restricts output to a single word instead of extra context.\n","Q: What does deconstructing a prompt reveal?\n","A: Its language, requirements, and constraints.\n","\n","KEY CONCEPTS:\n"," prompt types, constraints, context, length, tone, deconstruction, large language models, output refinement\n","Saved row 2\n","\n","================================================================================\n","PROCESSING ROW 3: LangGraph Crash Course #3 - Agents & Tools - Intro\n","================================================================================\n","\n","SUMMARY:\n"," AI agents are autonomous problem-solvers that decide their own steps, unlike chains or routers. They use tools—special functions like calculators or search—to act. The ReAct pattern (Reasoning + Acting) loops through think → action → observation until the LLM judges the answer complete; LangChain executes the chosen tool and returns results so the LLM retains full context. Combining an LLM’s reasoning with tools yields an agent, and upcoming sections will code a basic LangChain ReAct agent before exploring LangGraph improvements.\n","\n","TOPICS:\n"," ['Agentic AI', 'LangChain', 'Prompt Engineering']\n","\n","Q&A:\n"," Q: What differentiates an AI agent from a chain or router?\n","A: An agent autonomously decides its next steps, while chains/routers follow fixed instructions.\n","Q: What role do tools play in the ReAct pattern?\n","A: Tools are functions the agent can invoke; the LLM chooses which tool and its arguments, then observes the output.\n","Q: Why does LangChain execute the tool instead of the LLM?\n","A: To keep the LLM as the reasoning brain; LangChain runs the function and feeds results back for observation.\n","\n","KEY CONCEPTS:\n"," autonomous decision-making, ReAct pattern, think-action-observe loop, tool invocation, LLM reasoning, LangChain execution, agent tools, multi-step problem solving, context retention, function arguments\n","Saved row 3\n","\n","================================================================================\n","PROCESSING ROW 4: LangGraph Crash Course #9 - Reflection Agent - LangSmith Tracing\n","================================================================================\n","\n","SUMMARY:\n"," The instructor demonstrates tracing a reflection-agent system that iteratively refines a tweet for virality. Using LangSmith, each generate-and-critique step is streamed and visualized, showing six full cycles between a generation node and a reflection node. The final tweet emerges after successive critiques on context, emojis, hashtags, and engagement tactics.\n","\n","TOPICS:\n"," ['LangChain', 'Agentic AI', 'Prompt Engineering']\n","\n","Q&A:\n"," Q: What platform is used to trace the agent loops?\n","A: LangSmith at smith.langchain.com\n","Q: How many generate-critique cycles run?\n","A: Six iterations\n","Q: What environment variable must be set?\n","A: The LangSmith API key\n","\n","KEY CONCEPTS:\n"," reflection agent, LangSmith tracing, generate node, reflect node, viral tweet refinement, iterative critique, environment variables, API key, six iterations, streaming telemetry\n","Saved row 4\n","\n","================================================================================\n","PROCESSING ROW 5: LangChain Crash Course #7 - Chat Models - Setup\n","================================================================================\n","\n","SUMMARY:\n"," The instructor demonstrates setting up LangChain’s ChatOpenAI class to call OpenAI’s API. After installing langchain-openai and python-dotenv, the API key is stored in a .env file and loaded with load_dotenv. A ChatOpenAI instance is created with gpt-4o, invoked with a simple prompt, and the response content is extracted.\n","\n","TOPICS:\n"," ['LangChain', 'Prompt Engineering', 'Python Programming']\n","\n","Q&A:\n"," Q: How do you install the LangChain OpenAI package?\n","A: pip install langchain-openai\n","Q: What method loads environment variables from a .env file?\n","A: load_dotenv()\n","Q: Which attribute of the response object contains the model’s text reply?\n","A: response.content\n","\n","KEY CONCEPTS:\n"," ChatOpenAI, API key, .env file, load_dotenv, invoke method, response.content, gpt-4o, langchain-openai package\n","Saved row 5\n","\n","================================================================================\n","PROCESSING ROW 6: Python Training Course - Python Sort List\n","================================================================================\n","\n","SUMMARY:\n"," The video demonstrates Python’s list.sort() behavior on mixed-content lists: strings are grouped by case, with uppercase words alphabetically preceding lowercase ones, and numbers always precede strings. Reversing the sort inverts each subgroup while preserving the numeric-first order. The presenter advises normalizing case for uniform ordering and notes that the method gracefully handles heterogeneous lists.\n","\n","TOPICS:\n"," ['Other']\n","\n","Q&A:\n"," Q: How does Python sort a list of strings with mixed case?\n","A: Uppercase strings are sorted alphabetically first, followed by lowercase strings alphabetically.\n","Q: Where are numbers placed when sorting a list containing both numbers and strings?\n","A: Numbers are placed before all strings.\n","Q: What simple step ensures case-insensitive alphabetical ordering?\n","A: Convert all strings to the same case before sorting.\n","\n","KEY CONCEPTS:\n"," Python list.sort(), case-sensitive ordering, mixed-type sorting, uppercase precedence, numeric-first ordering, reverse sort behavior\n","Saved row 6\n","\n","================================================================================\n","PROCESSING ROW 7: Humans vs. AI: Who should make the decision?\n","================================================================================\n","\n","SUMMARY:\n"," The video explores when humans, AI, or a hybrid should make decisions, using fraud-detection alerts as a case study. AI excels at high-confidence predictions, humans outperform in uncertain middle zones, and augmented intelligence—human + AI—can surpass both if interface design mitigates automation bias. Presentation choices like forced vs. optional display and showing accuracy percentages strongly influence human trust and final accuracy.\n","\n","TOPICS:\n"," ['Artificial Intelligence', 'Data Science']\n","\n","Q&A:\n"," Q: When does a human outperform AI in fraud-alert triage?\n","A: At mid-range confidence scores where context and rarity matter.\n","Q: What is automation bias?\n","A: The tendency to over-rely on AI recommendations when they are forcibly displayed.\n","Q: How can optional display reduce bias?\n","A: By letting humans form an independent first impression before seeing AI advice.\n","\n","KEY CONCEPTS:\n"," confidence-score curves, automation bias, augmented intelligence, forced vs optional display, false-positive overload, human-AI teaming, decision presentation design, trust in probabilistic advice\n","Saved row 7\n","\n","================================================================================\n","PROCESSING ROW 8: Build generative apps faster with Vertex AI\n","================================================================================\n","\n","SUMMARY:\n"," Google Cloud’s Vertex AI launches six new APIs to streamline building grounded enterprise generative apps: document understanding, improved embeddings, hybrid vector search, ranking, grounded generation with citations, and fact-checking. They embed Google’s large-scale search and ads tech to boost accuracy and relevance while remaining modular for easy adoption. Developers can mix them with frameworks like LangChain or LlamaIndex to offload boiler-plate retrieval and grounding tasks and focus on unique features.\n","\n","TOPICS:\n"," ['Generative AI', 'Natural Language Processing', 'Prompt Engineering']\n","\n","Q&A:\n"," Q: What does the document understanding API do?\n","A: It parses complex documents (tables, sections, graphs) to improve retrieval and answer quality.\n","Q: How does the ranking API help an LLM?\n","A: It scores retrieved passages against the query to surface the most relevant evidence.\n","Q: Can developers use these APIs with LangChain?\n","A: Yes, Google is integrating them into LangChain and LlamaIndex for seamless prototyping.\n","\n","KEY CONCEPTS:\n"," grounded generation, vector search, embedding retrieval, ranking API, document understanding, fact-checking API, hybrid search, enterprise data, citations, stateless primitives\n","Saved row 8\n","\n","================================================================================\n","PROCESSING ROW 9: Unitary Transformations\n","================================================================================\n","\n","SUMMARY:\n"," The lecture explains that the SVD X = UΣVᵀ decomposes a matrix into unitary rotations and a scaling, where U and V preserve vector angles and lengths. Unitary transformations generalize the Fourier transform by rotating data into coordinate systems that simplify structure while preserving geometry. The economy-size SVD keeps only the non-zero singular values and corresponding columns, saving storage. Geometrically, X maps unit spheres into ellipsoids whose principal axes lengths and orientations are given by the singular values and left/right singular vectors.\n","\n","TOPICS:\n"," ['Natural Language Processing', 'Data Science', 'Statistics']\n","\n","Q&A:\n"," Q: What defining property makes U and V unitary?\n","A: UᵀU = UUᵀ = I and VᵀV = VVᵀ = I (identity matrices of appropriate sizes).\n","Q: How does multiplying a sphere by X change its shape?\n","A: It stretches the sphere into an ellipsoid whose axis lengths equal the singular values of X.\n","Q: When using complex data, what replaces the transpose in SVD?\n","A: The complex-conjugate transpose (denoted X* or U*, V*).\n","\n","KEY CONCEPTS:\n"," singular value decomposition, unitary matrix, economy-size SVD, Fourier transform, complex conjugate transpose, ellipsoid mapping, singular values, left/right singular vectors, angle and length preservation, geometric interpretation\n","Saved row 9\n","\n","================================================================================\n","PROCESSING ROW 10: Hands On With Google Gemini 1.5 Pro- Is this the Best LLM Model?\n","================================================================================\n","\n","SUMMARY:\n"," The video demonstrates building generative-AI apps with Google Gemini 1.5 Pro, highlighting its 1-million-token context window that supports text, images and long documents in a single model. After showing Google’s official demo of querying a 402-page Apollo 11 PDF and a sketch, the presenter walks through obtaining a free API key, installing the Python SDK, and calling generate_content for text and multimodal prompts. Code snippets illustrate unified text-and-image inference, streaming responses, and tips for integrating 1.5 Pro into RAG or PDF-query projects.\n","\n","TOPICS:\n"," ['Generative AI', 'Natural Language Processing', 'Python Programming']\n","\n","Q&A:\n"," Q: How do you obtain a free API key for Gemini 1.5 Pro?\n","A: Visit ai.google.com, click ‘Get API key’, and create one without a credit card.\n","Q: What context length does Gemini 1.5 Pro offer?\n","A: Up to 1 million multimodal tokens.\n","Q: Which Python method is used to generate content with Gemini 1.5 Pro?\n","A: model.generate_content()\n","\n","KEY CONCEPTS:\n"," Gemini 1.5 Pro, 1-million-token context, multimodal inputs, API key generation, generate_content method, streaming responses, unified text-image model, Python SDK, Apollo 11 PDF demo, RAG applications\n","Saved row 10\n","\n","================================================================================\n","PROCESSING ROW 11: How to evaluate large language models using Prompt Engineering | Testing and Improving with PyTorch\n","================================================================================\n","\n","SUMMARY:\n"," The session focuses on evaluating and testing prompt-engineering models built earlier, introducing metrics like perplexity, accuracy, and human evaluation to gauge performance. A hands-on example demonstrates computing these metrics on a small translation dataset, achieving 100 % accuracy. Debugging techniques, visualization tools, cross-validation, and continuous re-testing are recommended to refine and ensure generalization of the models before advancing to more complex prompt-engineering tasks.\n","\n","TOPICS:\n"," ['Prompt Engineering', 'Natural Language Processing', 'Machine Learning']\n","\n","Q&A:\n"," Q: What metrics are introduced to evaluate prompt-engineering models?\n","A: Perplexity, accuracy, and human evaluation.\n","Q: How is perplexity interpreted?\n","A: Lower values indicate better language-model predictions.\n","Q: Why test models on varied datasets?\n","A: To assess generalization to unseen data and tasks.\n","\n","KEY CONCEPTS:\n"," perplexity, accuracy, human evaluation, debugging prompt models, cross-validation, model generalization, translation dataset, continuous evaluation, visualization tools, fine-tuning\n","Saved row 11\n","\n","================================================================================\n","PROCESSING ROW 12: Generative AI vs AI agents vs Agentic AI\n","================================================================================\n","\n","SUMMARY:\n"," The talk clarifies three tiers of AI capability: Generative AI (an LLM that creates new content), AI agents (LLMs given tools and memory so they can autonomously complete narrow tasks like booking a flight), and Agentic AI (systems of one or more agents that coordinate, plan, and execute multi-step goals such as planning a full trip while checking visas and weather). Moving up the stack adds tool use, memory, and autonomous decision-making, enabling increasingly complex real-world actions.\n","\n","TOPICS:\n"," ['Generative AI', 'Agentic AI', 'Artificial Intelligence']\n","\n","Q&A:\n"," Q: What limits a basic LLM when asked for tomorrow’s flight price?\n","A: Its knowledge-cutoff date prevents access to live data.\n","Q: How does an AI agent differ from generative AI?\n","A: It uses tools and memory to autonomously complete tasks, not just answer questions.\n","Q: What characterizes an agentic AI system?\n","A: Multiple agents, multi-step planning, tool use, and autonomous goal pursuit.\n","\n","KEY CONCEPTS:\n"," knowledge cutoff, tool use, autonomous decision-making, multi-step planning, AI agent, agentic AI, LLM, API integration, task completion, travel booking\n","Saved row 12\n","\n","================================================================================\n","PROCESSING ROW 13: Covariance in Statistics\n","================================================================================\n","\n","SUMMARY:\n"," The lecture explains covariance as a statistic that quantifies how two random variables change together, using house size and price as an example. Positive covariance indicates both variables increase together, while negative covariance means one increases as the other decreases. The formula is derived from variance and interpreted geometrically by comparing each data point to the mean; however, covariance only reveals the direction, not the magnitude, of the relationship.\n","\n","TOPICS:\n"," ['Statistics', 'Machine Learning', 'Data Science']\n","\n","Q&A:\n"," Q: What does a positive covariance indicate about two variables?\n","A: Both variables tend to increase or decrease together.\n","Q: How is covariance related to variance?\n","A: Covariance of a variable with itself equals its variance.\n","Q: Why is Pearson correlation preferred after computing covariance?\n","A: It standardizes the measure to show both direction and strength of the linear relationship.\n","\n","KEY CONCEPTS:\n"," covariance formula, variance relation, mean centering, positive relationship, negative relationship, house size and price, Pearson correlation coefficient, data preprocessing\n","Saved row 13\n","\n","================================================================================\n","PROCESSING ROW 14: 3. Objective || End to End AI Tutorial\n","================================================================================\n","\n","SUMMARY:\n"," The video explains how to define objectives in reinforcement learning, emphasizing that the goal is to learn an optimal policy maximizing cumulative reward. It illustrates this with episodic tasks like Tic-Tac-Toe, where rewards are +1 for win, –1 for loss, 0 for draw, and continuous tasks like stock trading, where profit or risk-adjusted metrics serve as rewards.\n","\n","TOPICS:\n"," ['Reinforcement Learning', 'Machine Learning']\n","\n","Q&A:\n"," Q: What is the RL agent’s ultimate goal?\n","A: Maximize cumulative reward over time.\n","Q: How are rewards assigned in Tic-Tac-Toe?\n","A: +1 for win, –1 for loss, 0 for draw.\n","Q: Which metric can parameterize reward in stock trading?\n","A: Sharpe or Sortino ratio.\n","\n","KEY CONCEPTS:\n"," optimal policy, cumulative reward, reward function, episodic tasks, continuous tasks, Tic-Tac-Toe, stock trading, Sharpe ratio, trial-and-error learning, state-action pairs\n","Saved row 14\n","\n","================================================================================\n","PROCESSING ROW 15: Python Training - Python Dictionary Basics\n","================================================================================\n","\n","SUMMARY:\n"," The tutorial introduces Python dictionaries as collections of key-value pairs enclosed in curly braces, where keys must be immutable. It demonstrates creating dictionaries from literal syntax or by zipping two lists and converting with dict(), then shows how to access, modify, delete, and query keys, values, items, and length. Mastery of these operations is emphasized as foundational for later data-science work with pandas.\n","\n","TOPICS:\n"," ['Python Programming', 'Data Science']\n","\n","Q&A:\n"," Q: How do you create a dictionary from two lists?\n","A: Zip the lists and pass the result to dict(), e.g. dict(zip(keys, values)).\n","Q: What syntax retrieves the value for key 5?\n","A: d[5]\n","Q: Which method returns all key-value pairs?\n","A: .items()\n","\n","KEY CONCEPTS:\n"," key-value pairs, immutable keys, dict() constructor, zip function, access by key, modify value, delete entry, d.items(), d.keys(), d.values()\n","Saved row 15\n","\n","================================================================================\n","PROCESSING ROW 16: Fight Insider Threats with AI-infused SIEM\n","================================================================================\n","\n","SUMMARY:\n"," AI-driven User Behavior Analytics (UBA) embedded in IBM QRadar SIEM slashes breach containment time by 108 days and Insider-threat costs averaging $4.9 M. After a 7-day learning phase, machine-learning models profile normal user and peer behavior, flag anomalies, and auto-map them to MITRE ATT&CK tactics. Analysts review risk-ranked employees, watch-lists, and timeline-rich offense cards, then validate AI-generated IOCs, confidence scores, and relationship graphs in minutes. Human feedback continuously tunes the system, shifting SOC effort from reactive alert triage to proactive defense.\n","\n","TOPICS:\n"," ['Artificial Intelligence', 'Machine Learning', 'Data Science']\n","\n","Q&A:\n"," Q: How long does UBA need to learn user baselines?\n","A: Minimum 7 days.\n","Q: What was the average cost of an Insider threat?\n","A: $4.9 million.\n","Q: How much faster can AI reduce breach containment?\n","A: 108 days quicker.\n","\n","KEY CONCEPTS:\n"," User Behavior Analytics, Insider threats, QRadar SIEM, MITRE ATT&CK mapping, machine-learning anomaly detection, IOC confidence scoring, human-in-the-loop feedback, risk-ranked dashboards, automated investigation, No-text AI insights\n","Saved row 16\n","\n","================================================================================\n","PROCESSING ROW 17: Meta Llama 3 Is Here- And It Will Rule the Open Source LLM Models\n","================================================================================\n","\n","SUMMARY:\n"," Meta released Llama 3, an open-source large language model in 8B and 70B parameter versions trained on 50T tokens, doubling context length to 8K and outperforming comparable open models on benchmarks like MMLU, HumanEval, GSM8K and Math. Integrated into Meta AI, the model shows gains in reasoning, code generation, instruction following and reduced false refusals. Access requires approval via Meta’s website or Hugging Face, with weights, tokenizer and example inference code provided.\n","\n","TOPICS:\n"," ['Generative AI', 'Natural Language Processing', 'Artificial Intelligence']\n","\n","Q&A:\n"," Q: How many parameters do Llama 3 models have?\n","A: 8 billion and 70 billion\n","Q: What is the training token count for Llama 3?\n","A: 50 trillion tokens\n","Q: Where can users download Llama 3 weights?\n","A: Meta website or Hugging Face after approval\n","\n","KEY CONCEPTS:\n"," Llama 3, open-source LLM, 8B/70B parameters, 50T training tokens, 8K context length, Meta AI integration, benchmark performance, Hugging Face access\n","Saved row 17\n","\n","================================================================================\n","PROCESSING ROW 18: Getting Started With sklearn\n","================================================================================\n","\n","SUMMARY:\n"," The instructor rewinds to explain step-by-step how Python code produced a decision boundary, promising viewers will replicate it soon. The workflow starts with Google searches for scikit-learn (sklearn) documentation, focusing on the Naive Bayes algorithm. Gaussian Naive Bayes is identified as the specific classifier implemented.\n","\n","TOPICS:\n"," ['Machine Learning', 'Python Programming', 'Data Science']\n","\n","Q&A:\n"," Q: What library is used for the classifier?\n","A: scikit-learn (sklearn)\n","Q: Which Naive Bayes variant is chosen?\n","A: Gaussian Naive Bayes\n","Q: Where does the instructor first look for documentation?\n","A: Google\n","\n","KEY CONCEPTS:\n"," decision boundary, scikit-learn, Gaussian Naive Bayes, Python code, Google search, documentation, classifier\n","Saved row 18\n","\n","================================================================================\n","PROCESSING ROW 19: Log Normal Distribution in Statistics\n","================================================================================\n","\n","SUMMARY:\n"," The session reviews the Gaussian (normal) distribution and its bell-curve properties, then introduces the log-normal distribution, defined by the logarithm of the variable being normally distributed. Real-world examples—people’s income, product-review lengths—illustrate right-skewed log-normal data. Recognizing these shapes lets practitioners apply log-transformation followed by standardisation so all features share a common scale, boosting downstream model accuracy.\n","\n","TOPICS:\n"," ['Statistics', 'Data Science', 'Machine Learning']\n","\n","Q&A:\n"," Q: What defines a log-normal distribution?\n","A: A variable X is log-normal if ln(X) follows a normal distribution with some mean μ and σ.\n","Q: Why apply log transformation before standard scaling?\n","A: It converts log-normal data to normal, enabling standardisation to zero mean and unit variance.\n","Q: Name two practical datasets that follow log-normal behaviour.\n","A: Personal income and Amazon product-review lengths.\n","\n","KEY CONCEPTS:\n"," Gaussian distribution, bell curve, empirical rule, log-normal distribution, log transformation, standard normal distribution, standard scaler, feature scaling, right-skewed data, model accuracy\n","Saved row 19\n","\n","================================================================================\n","PROCESSING ROW 20: Deep learning project end to end | Potato Disease Classification Using CNN - 1 : Problem Statement\n","================================================================================\n","\n","SUMMARY:\n"," An end-to-end deep-learning project detects potato-plant diseases (early/late blight) from leaf photos to avert farmer losses. The pipeline collects images, augments them, trains a CNN in TensorFlow, exports via TF Serving, and wraps it in FastAPI. Quantized TF-Lite models power a React-Native mobile app through Google Cloud Functions, preceded by a React.js web demo. The series will cover data collection, MLOps, deployment choices, and GCP scaling across seven videos.\n","\n","TOPICS:\n"," ['Deep Learning', 'Mlops', 'Python Programming']\n","\n","Q&A:\n"," Q: What CNN-based pipeline will identify potato diseases?\n","A: TensorFlow CNN → TF Serving/FastAPI → TF-Lite quantized model → GCP Functions → React-Native app.\n","Q: Why apply data augmentation?\n","A: To expand limited leaf-image data via rotation, flip, contrast for robust CNN training.\n","Q: Why use TF-Lite quantization?\n","A: Shrinks model size, cuts memory, and speeds inference on mobile edge devices.\n","\n","KEY CONCEPTS:\n"," potato leaf disease detection, early blight, late blight, convolutional neural network, data augmentation, TF Serving, FastAPI, TF-Lite quantization, Google Cloud Functions, React-Native mobile app\n","Saved row 20\n","\n","================================================================================\n","PROCESSING ROW 21: LangGraph Crash Course #2 - Levels of Autonomy in LLM applications\n","================================================================================\n","\n","SUMMARY:\n"," \n","\n","TOPICS:\n"," ['Other']\n","\n","Q&A:\n"," \n","\n","KEY CONCEPTS:\n"," \n","Saved row 21\n","\n","================================================================================\n","PROCESSING ROW 22: Introduction to Advanced Topics in Prompt Engineering using Pre-Trained Large Language Models\n","================================================================================\n","\n","SUMMARY:\n"," The session advances from basic to expert-level prompt engineering, covering multimodal prompts (text, image, audio), fine-tuning tricks like multitask learning and distillation, and production deployment via TensorFlow Serving or Flask. It emphasizes rigorous data preprocessing—tokenization, normalization, augmentation—and ethical safeguards against bias, fairness, and privacy breaches. Hands-on Python examples demonstrate dog-breed classification with CNN backbones, multitask training loops, and knowledge distillation from T5-small, culminating in best-practice checklists for real-world application.\n","\n","TOPICS:\n"," ['Prompt Engineering', 'Deep Learning', 'Mlops']\n","\n","Q&A:\n"," Q: How does multitask learning improve prompt model robustness?\n","A: By training on several objectives simultaneously it learns shared representations that generalize better across diverse user inputs.\n","Q: What is the main benefit of knowledge distillation in deployment?\n","A: A compact student model mimics the large teacher, cutting latency and compute while preserving accuracy.\n","Q: Why normalize text during preprocessing?\n","A: Lower-casing and standard formatting reduce vocabulary variance, preventing confusion between identically-spelled tokens.\n","\n","KEY CONCEPTS:\n"," multimodal prompts, multitask learning, knowledge distillation, tokenization, text normalization, TensorFlow Serving, Flask API, bias mitigation, data augmentation, production deployment\n","Saved row 22\n","\n","================================================================================\n","PROCESSING ROW 23: SVD: Eigen Action Heros [Matlab]\n","================================================================================\n","\n","SUMMARY:\n"," The lecture demonstrates eigenfaces and SVD for face clustering by loading 20 grayscale 200×175 images each of Arnold Schwarzenegger and Sylvester Stallone, subtracting the mean “action-hero” face, and computing a 35 000×40 economy SVD. The leading eigenfaces capture dominant features (e.g., Terminator glasses); projecting every image into the first three principal components yields separable clusters, letting novel images be classified by proximity. Repeating the experiment with Taylor Swift shows stronger separation from Stallone than Arnold, while Arnold vs. Taylor clusters overlap more, highlighting how pixel correlations like skin tone can outweigh perceived human differences.\n","\n","TOPICS:\n"," ['Machine Learning', 'Data Science', 'Statistics']\n","\n","Q&A:\n"," Q: What preprocessing steps are applied to each image before building the data matrix?\n","A: Convert to grayscale, crop and align faces, reshape to 35 000-pixel column vectors, subtract the mean face.\n","Q: How are new images classified after the eigenfaces are computed?\n","A: Project the new image into the top three eigenface coordinates and assign it to the closer cluster (Arnold or Stallone).\n","Q: Why do Arnold and Taylor Swift overlap more than Arnold and Stallone in eigenface space?\n","A: Their lighter skin and hair colors produce higher pixel correlations, dominating the dot-product similarity.\n","\n","KEY CONCEPTS:\n"," eigenfaces, singular value decomposition, principal component analysis, mean face subtraction, image classification, clustering in face space, pixel correlation, 35 000-dimensional vectors, economy SVD, action-hero dataset\n","Saved row 23\n","\n","================================================================================\n","PROCESSING ROW 24: LangChain Crash Course #3 - What is LangChain?\n","================================================================================\n","\n","SUMMARY:\n"," LangChain is introduced as the most popular framework for bridging large language models with real-world actions like booking flights, querying databases, sending emails, and scraping websites. While standalone LLMs possess reasoning skills, they cannot interact with external systems, so LangChain supplies the necessary middleware to orchestrate these connections. The framework also offers model-agnostic development, letting developers swap LLMs without rewriting code.\n","\n","TOPICS:\n"," ['LangChain', 'Natural Language Processing', 'Agentic AI']\n","\n","Q&A:\n"," Q: What limitation of LLMs motivates the use of LangChain?\n","A: LLMs cannot directly interact with real-world APIs or perform actions like bookings.\n","Q: How does LangChain help developers switch between different LLMs?\n","A: It provides a model-agnostic framework so swapping models requires no code changes.\n","Q: Name two real-world tasks LangChain can enable an AI to perform.\n","A: Access booking APIs and send emails.\n","\n","KEY CONCEPTS:\n"," LLM limitations, real-world API interaction, model-agnostic framework, vacation planning example, middleware orchestration, booking APIs, database queries, email automation, web scraping, LangChain bridge\n","Saved row 24\n","\n","================================================================================\n","PROCESSING ROW 25: How To Use Residuals For Time Series Forecasting\n","================================================================================\n","\n","SUMMARY:\n"," The video explains how residual analysis helps diagnose and improve time-series forecasting models. Residuals—differences between fitted training values and actual observations—should show zero mean and no autocorrelation; detected bias or correlation signals model deficiencies. Using Python, the Holt-Winters model is fitted to airline-passenger data, then autocorrelation, Ljung-Box, and histogram tests reveal slight yearly seasonality and negligible negative bias, guiding model refinement.\n","\n","TOPICS:\n"," ['Time Series', 'Data Science', 'Python Programming']\n","\n","Q&A:\n"," Q: What distinguishes residuals from forecast errors?\n","A: Residuals are differences on the training data; errors are on unseen test data.\n","Q: Which two key properties should residuals exhibit?\n","A: Mean of zero and no autocorrelation.\n","Q: Which Python test quantifies residual autocorrelation?\n","A: The Ljung-Box test from statsmodels.\n","\n","KEY CONCEPTS:\n"," residuals, fitted values, autocorrelation, Ljung-Box test, Holt-Winters model, bias detection, time-series diagnostics, Python forecasting\n","Saved row 25\n","\n","================================================================================\n","PROCESSING ROW 26: Build a Text-to-SQL Agent for Smarter Database Queries\n","================================================================================\n","\n","SUMMARY:\n"," The tutorial demonstrates building a Text2SQL AI agent that converts natural language into SQL queries using LangGraph, LangChain, and watsonx.ai models. A Next.js frontend with Tailwind CSS provides a chat interface, while an in-memory SQLite database seeded with customer and order tables supplies data. The ReAct agent, configured with a GetFromDB tool and strict prompt guidelines, can answer questions like “how many customers do I have?” and “which customer placed the most orders?” by generating and executing SQLite queries.\n","\n","TOPICS:\n"," ['Natural Language Processing', 'LangChain', 'Python Programming']\n","\n","Q&A:\n"," Q: What tool does the agent use to interact with the database?\n","A: GetFromDB, a LangChain tool that executes SQL queries against the SQLite database.\n","Q: Which model is configured for the chat interface?\n","A: Mistral Large via watsonx.ai.\n","Q: How is the database schema provided to the LLM?\n","A: Embedded in the tool description and system prompt so the LLM knows tables, fields, and quoting rules.\n","\n","KEY CONCEPTS:\n"," ReAct agent, Text2SQL, LangGraph, SQLite in-memory database, watsonx.ai Mistral Large, Next.js frontend, GetFromDB tool, System prompt guidelines, Message serialization, SQL query generation\n","Saved row 26\n","\n","================================================================================\n","PROCESSING ROW 27: Learn Prompt Engineering from Scratch: Master the Art of Text Generation - Introduction\n","================================================================================\n","\n","SUMMARY:\n"," Prompt engineering is the NLP discipline of crafting inputs that coax large pre-trained language models into producing accurate, coherent, context-aware text for chatbots, translation and content generation. The course walks from basics—deconstructing prompts and spotting constraints—through fine-tuning models like GPT or BERT, weighing gains in output quality against risks of bias or ambiguity. By the end, learners will design, test and refine their own prompt pipelines.\n","\n","TOPICS:\n"," ['Prompt Engineering', 'Natural Language Processing', 'Generative AI']\n","\n","Q&A:\n"," Q: What is prompt engineering?\n","A: The practice of designing inputs that guide large language models to generate high-quality, contextually appropriate text.\n","Q: Why is prompt engineering important for chatbots?\n","A: It yields more accurate, coherent responses than rule-based methods, improving user experience and engagement.\n","Q: What limitations can prompt engineering models face?\n","A: They may struggle with complex or ambiguous prompts and can produce biased or inaccurate outputs due to data or architecture issues.\n","\n","KEY CONCEPTS:\n"," prompt engineering, large language models, fine-tuning, contextual coherence, bias mitigation, prompt deconstruction, content generation, chatbot responses\n","Saved row 27\n","\n","================================================================================\n","PROCESSING ROW 28: Q-learning - Explained!\n","================================================================================\n","\n","SUMMARY:\n"," Q-learning is a value-based, off-policy reinforcement learning algorithm that learns a state-action value function (Q-table) to maximize total reward. It uses temporal difference error to iteratively update Q values via the Bellman equation, balancing exploration through a behavior policy and exploitation via a target policy. The agent interacts with an environment, observes rewards, and refines its estimates over episodes until the Q values converge to an optimal policy.\n","\n","TOPICS:\n"," ['Reinforcement Learning', 'Machine Learning', 'Python Programming']\n","\n","Q&A:\n"," Q: What equation governs the update of Q values?\n","A: The Bellman equation with temporal difference error.\n","Q: Why is Q-learning called off-policy?\n","A: It separates the behavior policy for exploration from the target policy for optimal action selection.\n","Q: What does gamma control in Q-learning?\n","A: The discount factor that balances immediate versus future rewards.\n","\n","KEY CONCEPTS:\n"," Q-learning, state-action value function, Bellman equation, temporal difference error, behavior policy, target policy, off-policy algorithm, discount factor gamma, Q-table, episodes\n","Saved row 28\n","\n","================================================================================\n","PROCESSING ROW 29: Training Your Logistic Classifier\n","================================================================================\n","\n","SUMMARY:\n"," A logistic classifier is a linear model that predicts image labels by multiplying input pixels with learned weight matrix W and bias b. Training adjusts W and b so the raw scores (logits) for the correct class become high. These scores are converted to probabilities that sum to 1 via the softmax function, ensuring the target class probability approaches 1 while others approach 0.\n","\n","TOPICS:\n"," ['Machine Learning', 'Deep Learning', 'Python Programming']\n","\n","Q&A:\n"," Q: What operation turns input pixels into predictions in a logistic classifier?\n","A: A linear matrix multiply with weights W plus bias b.\n","Q: Why apply softmax to the logits?\n","A: To convert arbitrary scores into proper probabilities that sum to 1.\n","Q: What are the learnable parts of the model?\n","A: The weight matrix W and the bias vector b.\n","\n","KEY CONCEPTS:\n"," logistic classifier, linear function, matrix multiply, weights and bias, softmax, logits, probabilities, image classification, model training\n","Saved row 29\n","DONE. Final file: /content/drive/MyDrive/Final Thesis Code/Output/Zero Shot Prompting/kimi-k2-instruct-0905/kimi-k2-instruct-0905_zero_shot_full_output.xlsx\n","\n","Zero-shot Groq pipeline completed ✓\n"]}]},{"cell_type":"code","source":["#####################################################################\n","# 1. IMPORTS\n","#####################################################################\n","import os, re, json, warnings\n","import pandas as pd\n","import numpy as np\n","\n","from rouge_score import rouge_scorer\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from bert_score import score as bert_score\n","\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","\n","#####################################################################\n","# 2. SUPPRESS WARNINGS (BERTScore spam)\n","#####################################################################\n","warnings.filterwarnings(\"ignore\")\n","import logging\n","logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n","logging.getLogger(\"absl\").setLevel(logging.ERROR)\n","\n","\n","#####################################################################\n","# 3. PATHS (EDIT THESE)\n","#####################################################################\n","INPUT_FILE = \"/content/drive/MyDrive/Final Thesis Code/Input/clean_input_30.xlsx\"\n","OUTPUT_FILE = \"/content/drive/MyDrive/Final Thesis Code/Output/Zero Shot Prompting/kimi-k2-instruct-0905/kimi-k2-instruct-0905_zero_shot_full_output.xlsx\"\n","FINAL_EVAL_JSON = \"/content/drive/MyDrive/Final Thesis Code/Output/Zero Shot Prompting/kimi-k2-instruct-0905/evaluation_final.json\"\n","\n","print(\"Loaded input:\", INPUT_FILE)\n","print(\"Loaded model output:\", OUTPUT_FILE)\n","\n","\n","#####################################################################\n","# 4. GOLD TOPIC EXTRACTION (KEYWORD-BASED — FINAL VERSION)\n","#####################################################################\n","def gold_topics_from_ref_summary(ref_sum: str):\n","    text = (ref_sum or \"\").lower()\n","    matched = []\n","\n","    rules = [\n","        (\"Natural Language Processing\", [\n","            \"nlp\", \"bert\", \"transformer\", \"language model\", \"token\",\n","            \"text processing\", \"semantic\", \"embedding\"\n","        ]),\n","        (\"Artificial Intelligence\", [\n","            \"artificial intelligence\", \"ai system\", \"symbolic ai\",\n","            \"reasoning\", \"planning\", \"search\"\n","        ]),\n","        (\"Prompt Engineering\", [\n","            \"prompt\", \"few-shot\", \"zero-shot\", \"instruction\",\n","            \"cot\", \"chain-of-thought\", \"in-context learning\"\n","        ]),\n","        (\"Machine Learning\", [\n","            \"machine learning\", \"supervised\", \"unsupervised\", \"regression\",\n","            \"classification\", \"clustering\", \"features\"\n","        ]),\n","        (\"Deep Learning\", [\n","            \"deep learning\", \"neural network\", \"cnn\", \"rnn\",\n","            \"lstm\", \"gan\", \"transformer model\", \"backpropagation\"\n","        ]),\n","        (\"Reinforcement Learning\", [\n","            \"reinforcement\", \"policy gradient\", \"q-learning\",\n","            \"reward\", \"actor-critic\", \"rlhf\"\n","        ]),\n","        (\"Generative AI\", [\n","            \"genai\", \"text generation\", \"image generation\",\n","            \"diffusion\", \"sampling\", \"generation model\", \"llm\"\n","        ]),\n","        (\"Data Science\", [\n","            \"data science\", \"visualization\", \"feature\", \"pandas\",\n","            \"analysis\", \"data preprocessing\", \"eda\"\n","        ]),\n","        (\"Time Series\", [\n","            \"time series\", \"forecasting\", \"temporal\", \"trend\",\n","            \"seasonality\", \"arima\", \"prophet\", \"lag\"\n","        ]),\n","        (\"Statistics\", [\n","            \"statistics\", \"probability\", \"distribution\", \"variance\",\n","            \"hypothesis\", \"confidence interval\", \"p-value\"\n","        ]),\n","        (\"LangChain\", [\n","            \"langchain\", \"chain\", \"memory\", \"retriever\",\n","            \"agent executor\", \"llmchain\", \"prompt template\"\n","        ]),\n","        (\"Langraph\", [\n","            \"langraph\", \"workflow\", \"graph\", \"multi-agent orchestration\",\n","            \"node\", \"edge\", \"state graph\"\n","        ]),\n","        (\"Python Programming\", [\n","            \"python\", \"numpy\", \"matplotlib\", \"function\",\n","            \"loop\", \"list comprehension\", \"script\"\n","        ]),\n","        (\"Mlops\", [\n","            \"mlops\", \"deployment\", \"monitoring\", \"pipeline\",\n","            \"model registry\", \"cicd\", \"serving\"\n","        ]),\n","        (\"Agentic AI\", [\n","            \"agentic\", \"tool calling\", \"multi-agent\",\n","            \"planner\", \"agent\", \"reasoning agent\", \"autonomous\"\n","        ])\n","    ]\n","\n","    for label, keywords in rules:\n","        if any(kw in text for kw in keywords):\n","            matched.append(label)\n","\n","    return matched or [\"Other\"]\n","\n","\n","#####################################################################\n","# 5. TOKENIZER FOR QA & CONCEPTS\n","#####################################################################\n","STOPWORDS = set([\n","    \"the\",\"a\",\"an\",\"in\",\"on\",\"for\",\"to\",\"and\",\"or\",\"of\",\"with\",\"as\",\n","    \"by\",\"at\",\"from\",\"that\",\"this\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\n","    \"it\",\"its\",\"into\",\"about\",\"over\",\"under\",\"between\",\"across\",\n","    \"through\",\"their\",\"they\",\"you\",\"your\",\"we\",\"our\"\n","])\n","\n","def tokenize(text: str):\n","    return [\n","        t for t in re.findall(r\"[A-Za-z][A-Za-z0-9\\-_\\’']+\", text.lower())\n","        if t not in STOPWORDS\n","    ]\n","\n","\n","#####################################################################\n","# 6. FINAL EVALUATION FUNCTION  (FULL AND CORRECT)\n","#####################################################################\n","def evaluate(df_out: pd.DataFrame, df_ref: pd.DataFrame):\n","\n","    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n","    smooth = SmoothingFunction().method1\n","\n","    sum_r, sum_b, sum_bert = [], [], []\n","    overlap_acc_list, jaccard_list, micro_f1_list = [], [], []\n","    macro_f1_list, weighted_f1_list = [], []\n","    qa_bleu, qa_div, qa_ans = [], [], []\n","    kc_p, kc_r, kc_f = [], [], []\n","\n","    VALID_TOPICS = [\n","        \"Natural Language Processing\", \"Artificial Intelligence\", \"Prompt Engineering\",\n","        \"Machine Learning\", \"Deep Learning\", \"Reinforcement Learning\", \"Generative AI\",\n","        \"Data Science\", \"Time Series\", \"Statistics\", \"LangChain\", \"Langraph\",\n","        \"Python Programming\", \"Mlops\", \"Agentic AI\", \"Other\"\n","    ]\n","\n","    # for macro/weighted F1\n","    all_true, all_pred = [], []\n","\n","    for _, row in df_out.iterrows():\n","        idx = int(row[\"row_index\"])\n","        ref_summary = df_ref.loc[idx, \"Reference Summary\"] or \"\"\n","\n","        # -------------------- Summarisation --------------------\n","        gen_sum = row[\"summary\"] or \"\"\n","        r = rouge.score(ref_summary, gen_sum)['rougeL'].fmeasure\n","        b = sentence_bleu([ref_summary.split()], gen_sum.split(), smoothing_function=smooth)\n","\n","        with warnings.catch_warnings():\n","            warnings.simplefilter(\"ignore\")\n","            P, R, F1 = bert_score([gen_sum], [ref_summary], lang='en', verbose=False)\n","\n","        sum_r.append(r)\n","        sum_b.append(b)\n","        sum_bert.append(float(F1.mean()))\n","\n","        # -------------------- Topic Classification --------------------\n","        gold = gold_topics_from_ref_summary(ref_summary)\n","        pred = [x.strip() for x in (row[\"topic_classification\"] or \"\").split(\",\") if x.strip()]\n","\n","        set_pred = set(pred)\n","        set_gold = set(gold)\n","\n","        # Overlap Accuracy (your metric)\n","        overlap_acc = 1.0 if len(set_pred & set_gold) > 0 else 0.0\n","\n","        # Jaccard\n","        inter = len(set_pred & set_gold)\n","        union = len(set_pred | set_gold)\n","        jaccard = inter / union if union > 0 else 0.0\n","\n","        # Micro-F1\n","        tp = inter\n","        fp = len([p for p in pred if p not in gold])\n","        fn = len([g for g in gold if g not in pred])\n","\n","        prec = tp / (tp + fp) if (tp + fp) else 0.0\n","        rec  = tp / (tp + fn) if (tp + fn) else 0.0\n","        micro_f1 = (2 * prec * rec / (prec + rec)) if (prec + rec) else 0.0\n","\n","        overlap_acc_list.append(overlap_acc)\n","        jaccard_list.append(jaccard)\n","        micro_f1_list.append(micro_f1)\n","\n","        # Macro/Weighted F1 prep\n","        true_bin = [1 if t in gold else 0 for t in VALID_TOPICS]\n","        pred_bin = [1 if t in pred else 0 for t in VALID_TOPICS]\n","\n","        all_true.append(true_bin)\n","        all_pred.append(pred_bin)\n","\n","        # -------------------- Q&A --------------------\n","        qa_text = row[\"Q_and_A\"] or \"\"\n","        qs = [l[2:].strip() for l in qa_text.splitlines() if l.lower().startswith(\"q:\")]\n","\n","        gold_qs = [\n","            \"What is the main topic discussed in the video?\",\n","            \"Why is this topic important?\",\n","            \"How is the core concept explained?\",\n","            \"What example is mentioned in the content?\",\n","            \"What is the key conclusion of the video?\"\n","        ]\n","\n","        if qs:\n","            bleu_vals = [\n","                sentence_bleu([g.split()], q.split(), smoothing_function=smooth)\n","                for g in gold_qs for q in qs\n","            ]\n","            qa_bleu.append(np.mean(bleu_vals))\n","        else:\n","            qa_bleu.append(0.0)\n","\n","        toks = [t for q in qs for t in q.split()]\n","        qa_div.append(len(set(toks)) / len(toks) if toks else 0.0)\n","\n","        ref_tokens = set(tokenize(ref_summary))\n","        ans_count = sum(\n","            1 for q in qs\n","            if len(set(tokenize(q)) & ref_tokens) / max(1, len(tokenize(q))) >= 0.3\n","        )\n","        qa_ans.append(ans_count / len(qs) if qs else 0.0)\n","\n","        # -------------------- Key Concepts --------------------\n","        kc_text = str(row.get(\"key_concepts\", \"\") or \"\")\n","        pred_concepts = [c.strip().lower() for c in kc_text.split(\",\") if c.strip()]\n","\n","        ref_concepts = tokenize(ref_summary)\n","        ref_top = ref_concepts[:25]\n","\n","        tp_kc = len([p for p in pred_concepts[:10] if any(p in r or r in p for r in ref_top)])\n","\n","        p_val = tp_kc / 10\n","        r_val = tp_kc / len(ref_top) if ref_top else 0\n","        f1_val = (2*p_val*r_val/(p_val+r_val)) if (p_val+r_val) else 0\n","\n","        kc_p.append(p_val)\n","        kc_r.append(r_val)\n","        kc_f.append(f1_val)\n","\n","    # Compute macro/weighted F1\n","    all_true = np.array(all_true)\n","    all_pred = np.array(all_pred)\n","\n","    macro_f1 = precision_recall_fscore_support(all_true, all_pred, average=\"macro\", zero_division=0)[2]\n","    weighted_f1 = precision_recall_fscore_support(all_true, all_pred, average=\"weighted\", zero_division=0)[2]\n","\n","    return {\n","        \"Summarisation\": {\n","            \"ROUGE-L F1\": float(np.mean(sum_r)),\n","            \"BLEU\": float(np.mean(sum_b)),\n","            \"BERTScore F1\": float(np.mean(sum_bert))\n","        },\n","        \"Topic Classification\": {\n","            \"Overlap Accuracy\": float(np.mean(overlap_acc_list)),\n","            \"Jaccard Index\": float(np.mean(jaccard_list)),\n","            \"Micro F1\": float(np.mean(micro_f1_list)),\n","            \"Macro F1\": float(macro_f1),\n","            \"Weighted F1\": float(weighted_f1)\n","        },\n","        \"Q&A Generation\": {\n","            \"BLEU\": float(np.mean(qa_bleu)),\n","            \"Diversity\": float(np.mean(qa_div)),\n","            \"Answerability\": float(np.mean(qa_ans))\n","        },\n","        \"Key Concept Extraction\": {\n","            \"Precision@10\": float(np.mean(kc_p)),\n","            \"Recall@10\": float(np.mean(kc_r)),\n","            \"F1@10\": float(np.mean(kc_f))\n","        }\n","    }\n","\n","\n","#####################################################################\n","# 7. RUN EVALUATION\n","#####################################################################\n","df_ref = pd.read_excel(INPUT_FILE)\n","df_out = pd.read_excel(OUTPUT_FILE)\n","\n","eval_summary = evaluate(df_out, df_ref)\n","\n","print(\"\\n==================== FINAL EVALUATION METRICS ====================\")\n","for task, vals in eval_summary.items():\n","    print(f\"\\n{task}:\")\n","    for metric, value in vals.items():\n","        print(f\"  - {metric}: {value:.4f}\")\n","\n","with open(FINAL_EVAL_JSON, \"w\") as f:\n","    json.dump(eval_summary, f, indent=2)\n","\n","print(\"\\nSaved corrected evaluation JSON to:\", FINAL_EVAL_JSON)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0kE6XtTBvn2e","executionInfo":{"status":"ok","timestamp":1763913169313,"user_tz":-330,"elapsed":115647,"user":{"displayName":"Sarah Smruthi","userId":"05354743683624481075"}},"outputId":"2d27c347-1c32-477e-ddc7-d0937d5f3e0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded input: /content/drive/MyDrive/Final Thesis Code/Input/clean_input_30.xlsx\n","Loaded model output: /content/drive/MyDrive/Final Thesis Code/Output/Zero Shot Prompting/kimi-k2-instruct-0905/kimi-k2-instruct-0905_zero_shot_full_output.xlsx\n","\n","==================== FINAL EVALUATION METRICS ====================\n","\n","Summarisation:\n","  - ROUGE-L F1: 0.2448\n","  - BLEU: 0.0157\n","  - BERTScore F1: 0.8739\n","\n","Topic Classification:\n","  - Overlap Accuracy: 0.9333\n","  - Jaccard Index: 0.4032\n","  - Micro F1: 0.5369\n","  - Macro F1: 0.4909\n","  - Weighted F1: 0.5363\n","\n","Q&A Generation:\n","  - BLEU: 0.0207\n","  - Diversity: 0.8766\n","  - Answerability: 0.5889\n","\n","Key Concept Extraction:\n","  - Precision@10: 0.4267\n","  - Recall@10: 0.1707\n","  - F1@10: 0.2438\n","\n","Saved corrected evaluation JSON to: /content/drive/MyDrive/Final Thesis Code/Output/Zero Shot Prompting/kimi-k2-instruct-0905/evaluation_final.json\n"]}]}]}